\documentclass{article}

\usepackage[doublespacing]{setspace}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{syntax}
\usepackage{enumitem}

\begin{document}

\tableofcontents
\newpage

\begin{abstract}
\end{abstract}

\section{Introduction}

Python is a strong and dynamically typed language focused on simplicity and ease of use. Since its invention in the late 1980s, Python has exploded in popularity recently, seeing rapid adoption in both academia and industry. Its flexibility, not its speed, made it user-friendly. An increased interest in scientific computing and machine learning from the Python community led to the creation of packages such as \texttt{numpy} and \texttt{pytorch}, which expose high level APIs for high performance C code, enabling rapid development of machine learning and scientific computing applications.

More recently, Python's dynamic type system has been seen as a weakness rather than a strength. Runtime errors caused by type mismatches can be annoying or potentially disastrous for people deploying Python at scale. To combat this, type annotations were added directly to Python's syntax as part of Python 3.5 in 2014, and a typechecker --- \texttt{mypy} --- was developed to statically analyze the annotations. \texttt{mypy} eliminates a whole class of type errors from Python code but still allows for matrices with incompatible dimensions to be multiplied or applied together, resulting in runtime errors in machine learning or scientific computing code.

In this thesis, we propose a new extension to Python's type system that allows the expression of function signatures that respect the dimensions of matrices as they are passed into the function. This contribution further strengthens the type system and makes impossible runtime errors related to the dimensionality of matrices at function application sites.

\newpage

\section{Background}

\subsection{Python}

Python was conceived by Guido van Rossum in 1989 and was officially released to the public in 1991. Python is an interpreted language. Python has a strongly and dynamically typed system. Implicit type conversions are generally not performed and variables can be assigned to values with different types during runtime. Duck typing is allowed: if a method or line of code accesses an object's attribute or method, the runtime is happy to accept \textit{any} object that has an appropriately named method or attribute. Python is mainly an object-oriented and imperative language although it now has aspects of functional languages as well.

Python is well-known for its simplicity, readability, and ease-of-use. Python blocks are delimited by whitespace and its syntax closely resembles pseudocode. Large companies --- including Google, Instagram, and Dropbox --- all use Python in their systems or research due to its flexibility.

Some of the ethos of Python is best captured by quotes from ``The Zen of Python'' by Tim Peters (the poem can be accessed by typing \texttt{import this} into a Python REPL). ``Simple is better than complex.'' ``There should be only one-- and preferably only one --obvious way to do it.''

\subsection{\texttt{numpy} and other matrix libraries}

Python is adored for the speed of iteration it unlocks, but it is not without its shortcomings. Since it is an interpreted language, it can be difficult to write performant code. Ahead of time compilation is largely useless because of the dynamic typing. Python does have a bytecode format, which can speed up interpretation, but ultimately it lags far behind other  compiled languages in speed.

As more and more people began to use Python for scientific and machine learning purposes, its speed increasingly became a barrier. Methods such as JIT compilation were used to speed up execution. Additionally, the slowness led to the development of matrix libraries like \texttt{numpy} and machine learning libraries like \texttt{tensorflow} and \texttt{pytorch}. These libraries still expose high level APIs that are directly accessible from Python but call into highly optimized and parallel C code for the most expensive operations like back propagation and matrix multiplication.

The advent of these libraries has allowed engineers and researchers to continue to leverage the flexibility of Python while not sacrificing the speed of their execution and model training.

\subsection{\texttt{mypy} --- Python Typing}

Recently, static, strong typing has made a comeback in industry. In the 2000s (citation?), companies opted for dynamic languages like Javascript and Python. But as their systems grew, the dynamicism and flexibility of the types became a footgun, threatening the stability of their systems with dreaded runtime errors. Thus, came a wave of adoption of typed languages built on top of or compiled to these languages. TypeScript became a popular choice for former Javascript shops, and while at Dropbox, Guido --- the original inventor of Python --- helped extend Python's official syntax with type annotations in version 3.5 and helped write the accompanying official typechecker, \texttt{mypy}.

There are now several type checkers for Python including \texttt{pyre} from Facebook and \texttt{pytype} from Google. They are all gradual typing schemes. This means that types can optionally be added anywhere in the source files. For annotated code, the types can be checked. Elsewhere, types are assumed to be dynamic or unknown. This allows the typing to be incrementally adopted throughout a codebase, making it easy for users to opt in to checking where they want it without having to type their entire codebase. As of September 2019, Dropbox had reportedly typed 4 million lines of Python internally.

\texttt{mypy} supports basic types as expected. There are constructs to declare standard types like \texttt{int}, \texttt{string}, \texttt{list}, \texttt{tuple}, etc. Classes are also automatically promoted as types, and subtyping follows the inheritance patterns of classes. For more advanced type features, optional types are implemented via Python's \texttt{None} type. There is no explicit \texttt{Some} constructor, but the return of a non-\texttt{None} is considered a \texttt{Some}. There are also sum/union types provided via \texttt{Union}. Function types can also be overloaded via an \texttt{@overload} operator, allowing functions to be invoked with multiple different arguments and corresponding return types. \texttt{mypy} even supports a limited form of dependent typing in the form of \texttt{Literal}, which specifies that a variable may only be statically assigned to a constant. This in combination with \texttt{@overload} can provide surprisingly strong function types.

\subsection{Dependent and Refinement Types}

Python's type system is largely a standard one: types generally constrain a class of values, but further granularity is not possible. In comparison, dependent types allow for ``stronger'' types that can further constrain the space of well-typed programs. Refinement types are one such dependent type system, allowing the user to write predicates over values of a particular class to constrain them. Liquid Haskell is one such project that seeks to add refinement types to the programming language Haskell.

As an example, of the power of dependent types, and in particular, refinement types, consider the function that accepts a list and an integer for indexing into the list. In Python, the type of such a function can be seen in Figure \ref{python-type-indexing}.

\begin{figure}
\centering
\begin{verbatim}
A = TypeVar('A')
def index(lst: List[A], i: int) -> A: ... \end{verbatim}
\caption{\texttt{index} function type in Python}
\label{python-type-indexing}
\end{figure}
Such a type prevents improper indexing where the second argument is not an integer or where the first argument is not a list. However, such a type declaration still allows for runtime errors to occur, like the invocation \texttt{index([], 1)}. This will raise an \texttt{IndexOutOfBounds} error since \texttt{1} exceeds the maximum index of the empty list.

A stronger type --- one that is possible to declare in Liquid Haskell --- can statically prevent such malformed invocations. See Figure \ref{lh-type-indexing} for the declaration of the type. Although verbose, this type declaration prevents the misuse of the \texttt{index} function and statically raises a type error for the use \texttt{index [] 0}, which Python was unable to do.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ measure size @-}
{-@ size :: [a] -> {v : Int | v >= 0} @-}
size :: [a] -> Int
size [] = 0
size (h : t) = 1 + size t

{-@ index :: {l : [a] | true} -> {v : Int | v < size l && v >= 0} -> a @-}
index :: [a] -> Int -> a
index (h : t) i = if i == 0 then h else index t (i - 1)

test1 = index [1, 2, 3] 0
test2 = index [] 0 {- type error -}\end{verbatim}
    \caption{\texttt{index} function type in Liquid Haskell}
    \label{lh-type-indexing}
\end{figure}


\section{Shortcomings of Existing Type Systems}

The fundamental tension between these type systems is their expressiveness and specificity versus their verbosity and ease of use.

\subsection{\texttt{mypy}}

\texttt{mypy} takes a relatively lightweight approach to type checking. Its simplicity follows the ethos of Python quite closely. Even with its gradual  and sipmle approach, \texttt{mypy} is still able to eliminate a whole class errors, such as invoking functions with inappropriate arguments, accessing attributes that do not exist, or neglecting to check for the ``\texttt{None}-ness'' of function returns.

Still, as seen in Figure \ref{python-type-indexing}, Python still allows for rather obvious errors to occur, and this situation only becomes worse in the case of matrix types. As an example, the best \texttt{mypy} can do for matrix multiplication is seen in Figure \ref{python-type-matmul}. Here, the function type adds little information; it is unlikely that users will attempt to pass anything except \texttt{np.ndarray}. In the code contexts that \texttt{matmul} would occur, it is likely that almost \textit{all} objects are \texttt{np.ndarray}s. This type is so permissive of \texttt{np.ndarray}s that even matrices that do not have exactly two dimensions can be passed into the function without type errors being raised. The type signature does little to prevent runtime errors relating to the shape of the matrices.

\begin{figure}
    \centering
    \begin{verbatim}
import numpy as np

def matmul(x: np.ndarray, y: np.ndarray) -> np.ndarray: ...\end{verbatim}
    \caption{Sample \texttt{mypy} for \texttt{matmul}}
    \label{python-type-matmul}
\end{figure}


\subsection{Liquid Haskell}

Liquid Haskell (LH) has almost the opposite mentality of \texttt{mypy}. LH can represent extremely precise types and make very powerful static deductions about what can and cannot happen at runtime. However, this power and precision is also a downside. Declaring the proper types can be cumbersome and verbose. Furthermore, using these types in function types and then type checking them can be an expensive process. As an experiment, we declared the \texttt{np.nparray} in LH such that we could refer to the dimensions of the \texttt{np.nparray} in function signatures. The representation can be found in Figure \ref{lh-nparray}.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ LIQUID "--exact-data-con" @-}
{-@ LIQUID "--reflection" @-}
{-@ LIQUID "--ple" @-}

import Prelude hiding (reverse, max, drop)

{-@ type Nat = {v: Int | v >= 0} @-}

{-@ measure size @-}
{-@ size :: [a] -> Nat @-}
size :: [a] -> Int
size [] = 0
size (hd : tl) = 1 + size tl

data Vector a = V {vLen::Int, elts::[a]} deriving (Eq)
{-@ data Vector a = V {vLen::Nat, elts::{v : [a] | size v == vLen}} @-}
{-@ type VectorN a N = {v : Vector a | vLen v = N} @-}

{-@ type ListNE a = {v : [a] | size v > 0} @-}

{-@ measure head1 @-}
{-@ head1 :: ListNE Nat -> Nat @-}
head1 :: [Int] -> Int
head1 (h : t) = h

{-@ measure tail1 @-}
{-@ tail1 :: ListNE Nat -> [Nat] @-}
tail1 :: [Int] -> [Int]
tail1 (h : t) = t

data Nparray a = N {nDims::[Int], nElts::Either a (Vector (Nparray a))}

{-@ measure ords @-}
{-@ ords :: Nparray a -> [Nat] @-}
ords :: Nparray a -> [Int]
ords (N nDims _nElts) = nDims

{-@ measure isLeft @-}
isLeft (Left _) = True
isLeft (Right _) = False

{-@ data Nparray a =
 N {nDims::[Nat],
    nElts::{v : Either a (VectorN ({x : Nparray a | (tail1 nDims) == (ords x)}) {head1 nDims})
            | (isLeft v && size nDims = 0) || (not (isLeft v) && size nDims > 0) }} @-}

{-@ type NparrayN a N = {v : Nparray a | nDims v = N} @-}\end{verbatim}

    \caption{Sample implementation of the \texttt{np.ndarray} type in LH}
    \label{lh-nparray}


\end{figure}

This is not a fun representation to work with. Admittedly, little time was spent on making this representation as compact as possible, and we do not claim to be experts in Liquid Haskell. Still, in comparison to the entire Python typing ecosystem, it is clear that bolting on a full refinement type system would be a gross violation of Python's ethos of simplicity and ease of use.
\newpage

\section{A Simple Type Calculus for Matrix Dimensions}

How can we check matrix dimensions while maintaining the Python ethos? In this section, we introduce a new type as well as several operators to Python's type annotations that will enable checking of the dimensionality of matrices. The scope of the types is purposefully limited to matrices, to avoid the explosion in complexity of a more general system.

\subsection{Syntax}

\begin{figure}
    \centering
    \begin{grammar}
        <type> ::= \ldots
        \alt Nparray <dimension>*

        <dimension> ::= Id <string>
        \alt Int <int>
        \alt Add (<dimension>, <dimension>)
        \alt Mul (<dimension>, <dimension>)
        \alt Spread <string>
        \alt Drop (<string>, (<string> | <int>)*)
        \alt Keep (<string>, (<string> | <int>)*)

        <functionarg> ::= (<string>, <type>)

        <functiontype> ::= (<functionarg>*, <type>)

    \end{grammar}
    \caption{Full syntax for matrix types}
    \label{syntax}
\end{figure}


The major construct is a new \textbf{Nparray} type. This type represents a matrix of certain dimensions. It accepts a list of \textit{dimensions} to represent the concrete or abstract dimensions of the array. \textit{dimensions} have several constructs.
\begin{itemize}
    \item \textbf{Id} --- declares or references an abstract dimension of an array, one that can be of any non-negative length

    \item \textbf{Int} --- declares a dimension that must be exactly a certain size

    \item \textbf{Add} --- declares a dimensions that is the result of adding the sizes of previously declared dimensions. In Python syntax, can be represented by the \texttt{+} operator.

    \item \textbf{Mul} --- declares a dimensions that is the result of multiplying the sizes of previously declared dimensions. In Python, can be represented by the \texttt{*} operator.

    \item \textbf{Spread} --- declares or references an arbitrary number of dimensions that have arbitrary sizes. In Python, can be represented as \texttt{*A} where \texttt{A} could be an arbitrary variable name.

    \item \textbf{Drop} --- references an arbitrary number of dimensions declared by a \textbf{Spread} operation and allows the dropping of one or more of the captured dimensions.

    \item \textbf{Keep} --- references an arbitrary number of dimensions declared by a \textbf{Spread} operation and allows keeping one or more of the captured dimensions, discarding the rest.
\end{itemize}

We represent a function parameter type is a pair between a string --- the name of the parameter --- and a type. A function type is then a pair between a list of function parameter types and a return type.

For arguments to these function, we restrict to \textbf{Nparray} types which have a finite and known number of dimensions, essentially disallowing \textbf{Spread} and related \textit{dimensions} constructors. This currently restricts us to checking function applications and unable to verify the body of functions that use or return the \textbf{Nparray} constructor. Despite this limitation, we can still declare the types for many \texttt{numpy} functions and check their sequential applications. In future work, we can investigate lifting such restrictions and performing checking on function bodies.

See Figure \ref{syntax} for the formal syntax.

\subsection{Examples}

Suppose we would like to annotate the matrix multiplication function in Python with this new syntax. As a general description, matrix multiplication acts on two matrices with two dimensions each. The ``inner'' dimensions of the two matrices must be the same size. The result of the multiplication will be a matrix of two dimensions which correspond to the ``outer'' dimensions of the two original matrices. The definition along with some applications can be found, quite succinctly, in Figure \ref{np-type-matmul}. Here, we can see that the previous weaknesses in \texttt{mypy} allowing for the incorrect number of dimensions or dimensions that do not match has been caught statically.

\begin{figure}
    \centering
    \begin{verbatim}
def matmul(X: Nparray[A, B], Y: Nparray[B, C]) -> Nparray[A, C]: ...

X: Nparray[A, B, C]
Y: Nparray[A, B]
Z: Nparray[B, C]
W: Nparray[C, D]

matmul(X, Y) # will fail, number of dimensions incorrect
matmul(Y, Y) # will fail, inner dimensions don't work
res = matmul(X, Y) # will succeed
matmul(res, W) # will succeed, res inferred to have type Nparray[A, C]\end{verbatim}
    \caption{Typing of matrix multplication with new types}
    \label{np-type-matmul}
\end{figure}

As a demonstration of the \textbf{Spread} operator, we can also provide a typing annotation for one case of the \texttt{numpy.dot} operator. In this particular case, the first matrix can have an arbitrary number of dimensions. The second matrix must have exactly one dimension, which matches the last dimension of the first matrix. The return type is a matrix which has the same dimensions as the first matrix except the last dimension is removed. All this can be expressed in the type found in Figure \ref{np-type-dot}.

\begin{figure}
    \begin{verbatim}
def dot(X: Nparray[*A, B], Y: Nparray[B]) -> Nparray[*A]: ...

X: Nparray[1, 2, 3, 4]
Y: Nparray[5]
Z: Nparray[4]
W: Nparray[A, A, 5]

dot(X, Y) # will fail, last dimension doesn't match
dot(X, Z) # will succeed, result is Nparray[1, 2, 3]
dot(W, Y) # will succeed, result is Nparray[A, A]\end{verbatim}
    \caption{Typing of \texttt{np.dot} with new types}
    \label{np-type-dot}
\end{figure}

\subsection{Semantics}

We now provide a formal semantics for type checking the types defined above. There are three stores in the context: $\Gamma, \Sigma,$ and $\Pi$. They map single dimension variables to the argument's dimensions, spread variables to a list of argument dimensions, and parameter names to the argument types, respectively.

At a high level, checking falls into three steps:
\begin{enumerate}[label=\arabic*.]
    \item \textbf{Application checking} --- this checks a \textit{function type} against a list of \textit{arg types}. For each parameter in the function type, the type of the parameter is checked against the type of the corresponding argument. If each of the parameter types checks, then we can form the return type from the context. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{A} (param\_types, ret\_type), args : \Gamma', \Sigma', \Pi', \tau$$

    \item \textbf{Parameter/argument checking} --- this checks a specific parameter type against the provided argument type. If the parameter type is an integer, the type checking is straightforward. We simply check that the argument type is an integer, literal integer, or \textbf{Nparray} with 0 dimensions (which is equivalent to a scalar). If the parameter type is an \textbf{Nparray}, after verifying that the argument type is also an \textbf{Nparray}, we need to do further checking of the dimensions of the parameter and argument type. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{P} (type, arg\_type) : \Gamma', \Sigma', \Pi'$$


    \item \textbf{Dimension checking} --- this is the ``lowest'' level of the type checking. Here we will establish equalities and mappings between the dimensions required by the type and those provided in the arguments. For each of the dimension constructs, there are different typing rules. Let \textit{args} represent the dimensions of the argument type. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{D} (dimension, arg\_dimensions) : \Gamma', \Sigma', \Pi', rem\_dimensions$$

    \begin{itemize}
        \item \textbf{Id} \textit{i} --- if \textit{i} is not in $\Gamma$, then map $\Gamma[i \mapsto hd(args)]$ and continue type checking the remaining argument dimensions. If \textit{i} is in $\Gamma$, then prove that $\Gamma(i) = hd(args)$.

        \item \textbf{Int} \textit{i} --- prove that $i = hd(args)$.

        \item \textbf{Add} $(d_1, d_2)$ --- build arithmetic expressions from $d_1$ and $d_2$ resulting in $e_1$ and $e_2$. Prove that $e_1 + e_2 = hd(args)$.

        \item \textbf{Mul} $(d_1, d_2)$ --- build arithmetic expressions from $d_1$ and $d_2$ resulting in $e_1$ and $e_2$. Prove that $e_1 * e_2 = hd(args)$.

        \item \textbf{Spread} \textit{var} --- if \textit{var} is not in $\Sigma$, then find a split of \textit{args} into lists of types \textit{front} and \textit{back} such that $\Sigma[var \mapsto front]$ allows the remainder of type checking to succeed. If \textit{var} is in $\Sigma$, then split \textit{args} into \textit{front} and \textit{back} where $len(front) = len(\Sigma(var))$. For each element of \textit{front} and $\Sigma(var)$, prove that they are equal.

        \item \textbf{Drop} (\textit{var}, \textit{indices}) --- require that $var$ is in $\Sigma$. Convert \textit{indices} to a list of integers and drop those indices from $\Sigma(var)$. The indices can be pulled from $\Pi$ since arguments to the functions can be used to drop dimensions

        \item \textbf{Keep} (\textit{var}, \textit{indices}) --- require that $var$ is in $\Sigma$. Convert \textit{indices} to a list of integers and keep those indices in $\Sigma(var)$.
    \end{itemize}
\end{enumerate}

\begin{figure}
    $$\textsc{CheckAppEmpty}~\frac{\Gamma, \Sigma, \Pi \vdash_R ret : \tau}{\Gamma, \Sigma, \Pi \vdash_A ([], ret), [] : \Gamma, \Sigma, \Pi, \tau}$$

    $$\textsc{CheckApp}~\frac{\Gamma, \Sigma, \Pi[p \mapsto h_2] \vdash_P h_1, h_2 : \Gamma', \Sigma', \Pi' \qquad \Gamma', \Sigma', \Pi' \vdash_A (t_1, ret), t_2 : \Gamma'', \Sigma'', \Pi'', \tau}{\Gamma, \Sigma, \Pi \vdash_A ((p, h_1) :: t_1, ret), h_2 :: t_2 : \Gamma'', \Sigma'', \Pi'', \tau}$$

    $$\textsc{CheckParamScalarArrArr}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{Nparray}~[]) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarArrInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{Int}) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarArrLitInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{LiteralInt}~i) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarIntArr}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Int}, \textbf{Nparray}~[]) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarLitInt}~\frac{i = j}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{LiteralInt}~i, \textbf{LiteralInt}~j) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamArray}~\frac{\begin{gathered}\Gamma, \Sigma, \Pi \vdash_D h, \ell_2 : \Gamma', \Sigma', \Pi', rem \\ \Gamma', \Sigma', \Pi' \vdash_P (\textbf{Nparray}~\ell_1, \textbf{Nparray}~rem) : \Gamma'', \Sigma'', \Pi''\end{gathered}}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~h :: \ell_1, \textbf{Nparray}~\ell_2) : \Gamma'', \Sigma'', \Pi''}$$

    $$\textsc{CheckDimIdNotFound}~\frac{n \not\in \Gamma}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma[n \mapsto t], \Sigma, \Pi, t}$$

    $$\textsc{CheckDimIdFound}~\frac{n \in \Gamma \qquad \Gamma(n) = h}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimInt}~\frac{h = i}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Int}~i, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimAdd}~\frac{e_1 \qquad e_2 \qquad h = e_1 + e_2}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Add}~(d_1, d_2), h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimMul}~\frac{e_1 \qquad e_2 \qquad h = e_1 \cdot e_2}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Mul}~(d_1, d_2), h :: t) : \Gamma, \Sigma, \Pi, t}$$

    \caption{Formal semantics for type checking (part 1)}
    \label{semantics1}
\end{figure}

\begin{figure}
    $$\textsc{CheckDimSpreadNotFound}~\frac{n \not\in \Sigma}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Spread}~n, front @ back) : \Gamma, \Sigma[n \mapsto front], \Pi, back}$$

    $$\textsc{CheckDimSpreadFound}~\frac{n \in \Sigma \qquad len(front) = len(\Sigma(n)) \qquad front = \Sigma(n)}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Spread}~n, front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{CheckDimDrop}~\frac{n \in \Sigma \qquad \Pi \vdash_L \ell \rightsquigarrow \ell' \qquad drop(\Sigma(n), \ell') = front}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Drop}~(n, \ell), front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{CheckDimKeep}~\frac{n \in \Sigma \qquad \Pi \vdash_L \ell \rightsquigarrow \ell' \qquad keep(\Sigma(n), \ell') = front}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Keep}~(n, \ell), front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{RetInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Int} : \textbf{Int}}$$

    $$\textsc{RetLiteralInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{LiteralInt}~i : \textbf{LiteralInt}~i}$$

    $$\textsc{RetNparrayEmpty}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~[] : \textbf{Nparray}~[]}$$

    $$\textsc{RetNparrayFullId}~\frac{i \in \Gamma \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Id}~i :: t) : \textbf{Nparray}~(\textbf{Id}~i)}$$

    $$\textsc{RetNparrayFullInt}~\frac{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Int}~i :: t) : \textbf{Nparray}~()\textbf{Int}~i :: t')}$$

    $$\textsc{RetNparrayFullAdd}~\frac{\cdots}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Add}~(d_1, d_2) :: t) : \cdots}$$

    $$\textsc{RetNparrayFullMul}~\frac{\cdots}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Mul}~(d_1, d_2) :: t) : \cdots}$$

    $$\textsc{RetNparrayFullSpread}~\frac{n \in \Sigma \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Spread}~n :: t) : \Sigma(n) @ t'}$$

    $$\textsc{RetNparrayFullDrop}~\frac{n \in \Sigma \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell' \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Drop}~(n, \ell) :: t) : drop(\Sigma(n), \ell') @ t'}$$

    $$\textsc{RetNparrayFullKeep}~\frac{n \in \Sigma \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell' \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Keep}~(n, \ell) :: t) : keep(\Sigma(n), \ell') @ t'}$$

    $$\textsc{TransformListEmpty}~\frac{}{\Gamma \vdash_L [] \rightsquigarrow \ell}$$

    $$\textsc{TransformListInt}~\frac{\Gamma \vdash_L \ell \rightsquigarrow \ell'}{\Gamma \vdash_L i :: \ell \rightsquigarrow i :: \ell'}~i \in \mathbb Z$$

    $$\textsc{TransformListId}~\frac{s \in \Gamma \qquad \Gamma(n) = \textbf{LiteralInt}~i \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell'}{\Gamma \vdash_L s :: \ell \rightsquigarrow i :: \ell'}$$



\end{figure}



\section{Evaluation}

\subsection{Practicality}

\subsection{Implementation}

\subsection{Shortcomings}

\subsection{Future Work}

\section{Conclusion}

\end{document}
