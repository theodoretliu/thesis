\documentclass{report}

\usepackage{float}
\usepackage{url}
\usepackage[doublespacing]{setspace}
\usepackage[margin=1.5in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{syntax}
\usepackage{enumitem}
\usepackage{cite}


\begin{document}

\tableofcontents
\newpage

% \begin{abstract}
    Python is an extremely popular programming language used by many companies and academics around the world. Historically a slow language, it has gained popularity as an interface with high performance matrix and machine learning libraries. Although initially a strong, dynamically typed language, recent additions to Python have introduced a static type checker; however, the types are mostly useless when typing matrix operations. In this thesis, we develop a simple type calculus and extension to Python's type system that strengthens the static guarantees of the type checker over matrix operations while not sacrificing the simplicity and ease of use that is core to Python's spirit.
% \end{abstract}

\section{Introduction}

Python is a strong and dynamically typed language focused on simplicity and ease of use. Since its invention in the late 1980s, Python has exploded in popularity, seeing rapid adoption in both academia and industry. Its flexibility and approachable syntax made it user-friendly. An increased interest in scientific computing and machine learning from the Python community led to the creation of packages such as \texttt{numpy} and \texttt{pytorch}, which expose high level APIs for high performance C code, circumventing Python's slow execution and enabling rapid development of machine learning and scientific computing applications.

More recently, Python's dynamic type system has been seen as a weakness rather than a strength. Runtime errors caused by type mismatches can be annoying or potentially disastrous for people deploying Python at scale. To combat this, type annotations were added directly to Python's syntax as part of Python 3.5 in 2014, and a reference typechecker --- \texttt{mypy} --- was developed to statically analyze the annotations. \texttt{mypy} eliminates a whole class of type errors from Python code but is not powerful enough to reject matrices with incompatible dimensions from being multiplied or applied together, resulting in runtime errors in machine learning or scientific computing code.

In this thesis, we propose a new extension to Python's type system that allows the expression of function signatures that respect the dimensions of matrices as they are passed into the function. This contribution further strengthens the type system and makes impossible runtime errors related to the dimensionality of matrices at function application sites.


\chapter{Background and Related Work}

\section{Type Systems}

A type system in a programming language is a form of program analysis where labels called \textbf{types} are assigned to values and expressions. By reasoning about these types, the system can enforce properties about the execution of programs within the language. Types can be thought of as a set of values that a variable or expression can take, and type checking is the process of determining whether a value or set of values belongs to the set declared or specified. Type systems can range from the simple to the complex and are usually designed with certain properties in mind. The simply typed lambda calculus introduced by Church only had function types but guaranteed that the left sides of applications were always functions and that every expression had a normal form \cite{Church1940AFO}. In contrast, Rust-lang's ownership and type system is able to not only prove that its programs invoke functions with the correct arguments but also that concurrent accesses to memory are safe \cite{rustlang}.

In the remainder of this section, we will examine several dichotomies and classes of type systems that will be relevant later in this paper.

\subsection{Static versus Dynamic Type Systems}

In a \textbf{static type system}, the types of a program are checked during the compilation of the program. The type of a function or variable is constant throughout the lifetime of program. The types can be annotated directly or inferred. A static system ensures that no runtime errors relating to the types will occur during the execution of a compiled program. Static type systems benefit greatly from this guarantee and can also use the type information during compilation to perform optimizations. Additionally, type information can be stripped away in the final executable, reducing the size of the resulting program. However, static type systems can be difficult to implement, and their speed slows and complexity grows as the types they seek to support become more complex. C/C++, OCaml, and Rust are examples of languages with static type systems.

In a \textbf{dynamic type system}, the types of values are checked during the execution of a program. Variables can be reassigned to multiple types. Runtime errors will be thrown if there are operations between incompatible types, such as attempting to add a string and a float. Dynamic type systems are good for their flexibility and ease of implementation; there is no need for type checking or inference ahead of execution. However, their lack of runtime guarantees can be difficult to handle, especially in mission-critical software. Without knowing whether a program can fail in a myriad of ways at runtime makes it hard to have confidence in its deployment. Python (traditionally), Ruby, and Javascript are languages with dynamic type systems.

\subsection{Strong versus Weak Type Systems}

A \textbf{strong type system} enforces that the type expected at a particular program location exactly matches the type found. In other words, no implicit conversions are done between types to make function calls or assignments well-typed. If there are mismatches found, an error either during compilation or runtime is raised. Strong type systems prevent users from accidentally misusing variables or performing computations they did not intend. Users need to bear the additional cost of needing explicit type casts or conversions whenever a type \textit{actually} needs to be used as a different type. Python and OCaml are languages with strong type systems.

A \textbf{weak type system} attempts to perform certain type conversions implicitly if types do not match as expected. This eliminates the need for constant massaging between various types --- such as when wanting to print an integer --- but can have disastrous consequences. As an example, Javascript has an infamous weak type system, leading to bizarre and unexpected results from inocuous statements like \texttt{12 + "21" == "1221"}. PHP is another example of a weakly typed language.

\subsection{Other Type Systems}
\paragraph{Duck Typing}

Duck typing receives its name from the classic phrase: ``If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.'' In programming languages, this means the type system does not care about the specific label or class a value belongs to as long as it has certain attributes or implements certain methods. As an example, if we have expression \texttt{x.f()} in a duck typing system, it does not matter whether \texttt{x} is of class A or B or a primitive type, as long as it has a callable method called \texttt{f}. Python is a duck typed language.

\paragraph{Gradual Typing}

In a gradually typed language, type annotations are optional. Wherever type annotations are present, type checking is performed. For unannotated code, type checking is either elided or a generic type of \textit{any} is inferred \cite{PythonDropbox}. Gradual type systems allow the incremental adoption of typing in a codebase. Instead of having to type every line of code in a codebase at once, small parts can be annotated and statically checked while the remaining code falls back to runtime checks. Thus, gradual typing achieves a balance between static and dynamic typing. TypeScript and Python with \texttt{mypy} are languages with gradual typing.

\paragraph{Dependent and Refinement Types}

Dependent type systems extend traditional type systems by allowing values from the language be a part of the type. This allows further specificity of the sets of values that can inhabit a type. As an example,the traditional type \texttt{List int} represents the set of all lists of any length that contain only integers. An analagous dependent type might be \texttt{List int 4}, denoting the set of integer lists which have exactly length 4. We can take this dependent type further with a function

\begin{singlespace*}\begin{center}
    \texttt{def f(x: int) -> List int x: ...}
\end{center} \end{singlespace*}
which represents a function who accepts an integer and returns a list of exactly the length provided. Dependent types allow us to powerfully reason about the static properties of our language and will useful in our reasoning about matrix dimensions later.

Refinement types are a form of dependent types in which the set of values in a type can be filtered by predicates attached to a type. One refinement type system is Liquid Haskell (LH), which embeds refinement types in the Haskell programming language \cite{Jhala2014RefinementTF}. Refinement types offer a convenient way to declare specific types, and we explore this further in a later section.

As a demonstration of the power of refinement types (and also their potential weakness), consider the function that accepts a list and an integer for indexing into the list. In a simple type system, the type of such a function might be:

\begin{singlespace*}
\begin{center} \texttt{def index(lst: List[A], i: int) -> A: ...} \end{center} \end{singlespace*}

This type prevents improper indexing where the second argument is not an integer or where the first argument is not a list. However, this type declaration still allows for runtime errors to occur, like the invocation \texttt{index([], 1)}. This will raise an exception since \texttt{1} exceeds the maximum index of the empty list.

A stronger type --- one that is possible to declare in Liquid Haskell --- can statically prevent such malformed invocations. See Figure \ref{lh-type-indexing} for the declaration of the type. This type declaration prevents the misuse of the \texttt{index} function and statically raises a type error for the use \texttt{index [] 0}, which Python was unable to do. However, it is clear that the cost of such expressiveness is increased verbosity in the type declaration.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ measure size @-}
{-@ size :: [a] -> {v : Int | v >= 0} @-}
size :: [a] -> Int
size [] = 0
size (h : t) = 1 + size t

{-@ index :: {l : [a] | true} -> {v : Int | v < size l && v >= 0} -> a @-}
index :: [a] -> Int -> a
index (h : t) i = if i == 0 then h else index t (i - 1)

test1 = index [1, 2, 3] 0
test2 = index [] 0 {- type error -}\end{verbatim}
    \caption{\texttt{index} function type in Liquid Haskell}
    \label{lh-type-indexing}
\end{figure}


\section{Python}

In this section, we examine some of Python's history and design philosophy, its type system, and its matrix and machine learning libraries.

\subsection{History and Design Philosophy}

Guido van Rossum began work on Python in 1989, and it was officially released to the public in 1991. Python is an interpreted language. It has a strong and dynamic type system. Type errors are raised at runtime, like when a string and an integer are added together. Variables can be assigned to values with different types during runtime. Python allows duck typing: if a method or line of code accesses an object's attribute or method, the runtime is happy to accept \textit{any} object that has the appropriately named method or attribute. Python is mainly an object-oriented and imperative language although it now has aspects of functional languages as well.

Python is well-known for its simplicity, readability, and ease-of-use, and these attributes are fundamental to its spirit. In fact, Python Enhancement Proposal (PEP) 20 --- Python's official format for reviewing and accepting changes to the language --- makes the following aphorisms, collectively called ``The Zen of Python,'' a part of the Python spec \cite{pep20}:

\begin{singlespace*}
\begin{quote}
    Beautiful is better than ugly. \\
    Explicit is better than implicit. \\
    Simple is better than complex. \\
    Complex is better than complicated. \\
    Flat is better than nested. \\
    Sparse is better than dense. \\
    Readability counts. \\
    Special cases aren't special enough to break the rules. \\
    Although practicality beats purity. \\
    Errors should never pass silently. \\
    Unless explicitly silenced. \\
    In the face of ambiguity, refuse the temptation to guess. \\
    There should be one-- and preferably only one --obvious way to do it. \\
    Although that way may not be obvious at first unless you're Dutch. \\
    Now is better than never. \\
    Although never is often better than *right* now. \\
    If the implementation is hard to explain, it's a bad idea. \\
    If the implementation is easy to explain, it may be a good idea. \\
    Namespaces are one honking great idea -- let's do more of those!
\end{quote}
\end{singlespace*}
These aphorisms can be accessed from any Python REPL via the command \texttt{import this}.

Python design seems to carefully follow the above mantra. Python blocks are delimited by whitespace and its syntax closely resembles pseudocode. Variable types are never explicitly declared, memory is automatically managed and garbage collected, returning different types from functions is allowed. Python allows a programmer to sanely accomplish whatever they want with little friction. Large companies and academics --- including Google, Instagram, and Dropbox --- all use Python in their systems or research \cite{python-quotes}.

\subsection{\texttt{numpy} and other matrix libraries}

Python unlocks a much faster speed of iteration, but it has its shortcomings. Since it is an interpreted language, it can be difficult to achieve performant code. Python does have a bytecode format which can speed up interpretation, but it is order of magnitudes slower than other compiled languages.

As more and more people began to use Python for scientific and machine learning purposes, its speed increasingly became a barrier. This slowness led to the development of the library \texttt{numpy} which exposes a high-level API for declaring and operating on multi-dimensional matrices. \texttt{numpy} achieves fast performance by implementing all of its algorithms in highly optimized and low-level code and then linking those into Python. Machine learning libraries such as \texttt{pytorch} and \texttt{tensorflow} took similar approaches, providing high-level APIs for model training while using optimized GPU code to provide speed and parallelism. In a future section, we will further explore the objects and operations that are exposed by these libraries.

The advent of these libraries has allowed engineers and researchers to continue to leverage the flexibility of Python while not sacrificing the speed of their execution and model training.

\subsection{\texttt{mypy} --- Python Typing}

Recently, dynamic typing in Python has become seen as a weakness rather than a strength, especially in large organizations. While Python's flexibility initially made development fast and easy, this did not scale as more engineers began to work on the codebase. Not only were runtime type errors possible, it was also difficult to look at functions and immediately determine their expectations for the type of their inputs and outputs. This emphasizes the fact that types not only function as a form of safety for a program but also as a form of self-documentation. Jukka Lehtosalo recognized these weaknesses and, with the help of Guido and others, developed a static type system and gradual type checker for Python --- \texttt{mypy}. As part of PEP 484, Python was officially extended with type annotation in version 3.5 in 2015 \cite{pep484}.

There are now several type checkers for Python including \texttt{pyre} from Facebook and \texttt{pytype} from Google. As of September 2019, Dropbox had reportedly typed 4 million lines of their Python code \cite{PythonDropbox}.

We now give an overview of the types that \texttt{mypy} supports.
\begin{itemize}
    \item \textbf{Primitives} --- Python's primitive types such as \texttt{int}, \texttt{float}, \texttt{bool}, and \texttt{str}.

    \item \textbf{Collections} --- Python's standard collections like lists, dictionaries, tuples, and sets are supported. They are declared as \texttt{List[Type]}, \texttt{Dict[Type1,Type2]}, \texttt{Tuple[Type]}, and \texttt{Set[Type]}, respectively. These types are parameterized and can be instantiated with different types.

    \item \textbf{Classes and Objects} --- all declared classes are automatically promoted to types, meaning that functions can accept parameters of certain classes. Furthermore, inheritance is automatically viewed as a form of subtyping. As an example,

    \begin{singlespace*}
    \begin{verbatim}
class A:
    pass

class B(A):
    pass

def f(x: A):
    return None

b = B()
f(b) # will type check\end{verbatim}
    \end{singlespace*}
    In the example, all instances of class \texttt{B} are subtypes of class \texttt{A}, so instances of class \texttt{B} can stand in for class \texttt{A} as seen in function \texttt{f} and its application to \texttt{b}.

    \item \textbf{Union types} --- union types are created via the \texttt{Union[Type1, Type2]} operator, allowing a value to be assigned to something from either of the two types.

    \item \textbf{Option types} --- \texttt{mypy} also provides support for option types via \texttt{Optional[Type]}. Although languages with option types typicall have explicit \texttt{None} and \texttt{Some x} constructors, Python simplifies this by having a \texttt{None} and a bare value \texttt{x} for the \texttt{Some} case.

    \item \textbf{Duck typing} --- Python is a duck-typed language, and \texttt{mypy} makes this support explicit. For example, the type \texttt{Iterable[Type]} accepts any object which implements the \texttt{.next()} method and returns the type \texttt{Type}. Similarly, \texttt{Mapping[Type1, Type2]} accepts any object which implements the method \texttt{.__getitem__(x: Type1)} and returns the type \texttt{Type2}. In both of these examples, the exact type of the object does not matter, only that it implements a specific set of methods.

    \item \textbf{Function overloading} --- in \texttt{mypy}, function signatures can be overloaded, meaning that functions can have multiple signatures. This is enabled via the \texttt{@overload} decorator on function. As an example:

    \begin{singlespace*}
    \begin{verbatim}
@overload
def f(x: int) -> str: ...

@overload
def f(x: str) -> int: ...

def f(x: Union[int, str]) -> Union[int, str]:
    if isinstance(x, int):
        return "hello"

    return 1

f(1) # will type check with type str
f('hello') # will type check with type int\end{verbatim}
    \end{singlespace*}
    Because of the \texttt{overload}, \texttt{mypy} is able to infer a much more specific type for each of the function calls rather than just \texttt{Union[int, str]}.

    \item \textbf{Literal values} --- \texttt{mypy} is not a general dependent type checker, but it does have a construct \texttt{Literal[Value]} which requires that a parameter or variable be assigned to exactly the value specified in the \texttt{Literal} constructor. For example,

    \begin{singlespace*}
        \begin{verbatim}
x : Literal[1]

x = 1 # will type check
x = 2 # will not type check
x = 3 - 2 # will not type check\end{verbatim}
    \end{singlespace*}
    Note that although in the last line above, it is ``obvious'' that \texttt{x} is being assigned to 1, \texttt{mypy} performs no reasoning or speculation about the result of $3 - 2$. This is limiting but greatly simplifies the task of type checking \texttt{Literal} constructors.

\end{itemize}

From above, we can see that Python's type system is fairly straightforward. Besides the \texttt{Literal} constructor, Python features no dependent types. This is seemingly a conscious choice; Python invokes its own ethos as described in ``The Zen of Python'' and opts for a type system that is easy to check and declare rather than one that provides the most powerful guarantees.

\section{Matrix library objects and operations}

\subsection{Multidimensional arrays}
\label{multidimensional}

The fundamental object for storing data in matrix and machine learning libraries like \texttt{numpy} and \texttt{pytorch} is the \textbf{multidimensional} or \textbf{N-dimensional array}. In linear algebra, the fundamental elements are vectors and matrices. Vectors are arrays of numbers. Matrices are arrays of arrays of numbers. \texttt{numpy} generalizes these constructs to an arbitrary number of ``arrays of arrays of arrays of ... of numbers.''. With this generalization, vectors are multidimensional arrays with one dimension, and matrices are multidimensional arrays with two dimensions. Solo scalars can even be represented by multidimensional arrays with zero dimensions. The number of dimensions and the size of each dimension the array is represented by a tuple of integers which is generally referred to as its \textbf{shape} \cite{ndarray}.

To see why this representation is useful, we look at some examples. A vector of length 10 is represented by a shape of $(10,)$. A $2 \times 2$ matrix is represented by a shape of $(2, 2)$. A dataset of 1000 $256 \times 256$ resolution images, each with distinct RGB channels, could be represented by the shape $(1000, 3, 256, 256)$. The scalar $1$ is also a multidimensional array with shape $(,)$ (the empty tuple).

\subsection{Operations on Multidimensional Arrays}
\label{ndarray-operations}

\texttt{numpy} and related libraries define many operations over these multidimensional arrays. We cover some of the more useful and common operations here \cite{numpy-manual}.

\begin{itemize}
    \item \textbf{Broadcasting} --- a unique operation between multidimensional arrays that does not have a linear algebra interpretation. Broadcasting occurs whenever there is a binary infix operator --- such as +, -, /, etc. --- acting between two arrays or there is assignment from one array to a slice of another.

    To determine whether two arrays can broadcast, we start with the \textit{last} dimensions of both arrays. We continue pairing the dimensions of both arrays until one or both run out of dimensions to pair. For each pair of dimensions, the dimensions must be equal or at least one of the dimensions must be equal to one. If broadcasting succeeds, the resulting array has the same number of dimensions as the longer of the two original arrays. The dimensions of the final array are the maximum of the two original arrays' dimensions.

    Broadcasting is a strange but pragmatic operation. It makes it simple to multiply an entire array by a constant value, like \texttt{2 * X}, or even perform more complicated operations, like adding the same vector to each row of a matrix.

    \item \textbf{Generalized dot product} --- the dot product definition depends on the shape of the arrays it is operating on.
    \begin{itemize}
        \item If both arrays are vectors, it is the traditional dot product.
        \item If both arrays are matrices, it is matrix multiplication.
        \item If either array is scalar, it is equivalent to scalar multiplication.
        \item If the first array has $N$ dimensions and the second array has 1 dimension, the result is valid if the last dimension of the first array matches with the single dimension of the second array.
        \item If the first array has $N$ dimensions and the second array has $M$ dimensions, the result is valid if the last dimension of the first matrix and the second-to-last dimension of the second matrix are the same.
    \end{itemize}

    \item \textbf{Summation, Euclidean norm} --- array summation and the Euclidean norm are different operators, but they reduce the dimensions of an array the same way. If given no additional arguments, summation reduces an array to a scalar or an array with zero dimensions. If given an axis, the summation only sums along that particular axis, removing the provided dimension index from the shape.

    \item \textbf{Zeros, Ones} --- given a tuple of integers, \texttt{np.zeros} generates a multidimensional array of zeros with shape exactly equal to the tuple given. \texttt{np.ones} acts analogously.

    \item \textbf{Concatenation} --- takes two arrays and an axis and returns the result of concatenating those arrays along the axis. For concatenation to succeed, the dimensions of the two arrays must agree for all indices except for the one on which they are concatenated.

    \item \textbf{Model training} \cite{sklearn} --- in supervised model training, the model is usually fed the data, $X$, and a list of labels, $y$.In order for the training to succeed, the number of data points in $X$ must match the number of labels in $y$.
\end{itemize}
These are just a small sample of the operations we can perform on multidimensional arrays, but they are exactly the operations we would like to more strongly type in Python.

\subsection{\texttt{numpy} operations in \texttt{mypy}}

We can examine how we can type some \texttt{numpy} operations using \texttt{mypy}'s current capabilities. For the \texttt{np.dot} function described above, the most specific type we can write is
\begin{center}
    \texttt{def dot(a: np.ndarray, b: np.ndarray) -> np.ndarray: ...}
\end{center}
Although this signature will prevent nonsensical calls to \texttt{np.dot} with \texttt{str} arguments, it does not capture the most interesting part of the operation. Fundamentally, what we care about is the underlying \textit{shape} of the multidimensional arrays and how those shapes do or do not match to correctly dot together. For any other multidimensional array functions, the signature will look very similar, with \texttt{mypy} only able to restrict to the class \texttt{np.ndarray} and no further.

\subsection{Multidimensional arrays in Liquid Haskell}

As an experiment in the expressivity of Liquid Haskell and the practicality of refinement types, we attempt to express a strict type for multidimensional arrays. The resulting code can be found in Figure \ref{lh-nparray}. There are a couple things to note here. First, this representation has the desired property that the shape of the multidimensional array is a part of the matrix type. Refinement and dependent types have lifted the shape value into the type, which will allow us to refer to the shape as part of our type signatures for array operations. Second, the representation is \textit{long}. LH's power and type expressivity have allowed us to express this complicated type, but there is an explosion in verbosity and complexity as a result.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ LIQUID "--exact-data-con" @-}
{-@ LIQUID "--reflection" @-}
{-@ LIQUID "--ple" @-}
import Prelude hiding (reverse, max, drop)

{-@ type Nat = {v: Int | v >= 0} @-}
{-@ measure size @-}
{-@ size :: [a] -> Nat @-}
size :: [a] -> Int
size [] = 0
size (hd : tl) = 1 + size tl

data Vector a = V {vLen::Int, elts::[a]} deriving (Eq)
{-@ data Vector a = V {vLen::Nat, elts::{v : [a] | size v == vLen}} @-}
{-@ type VectorN a N = {v : Vector a | vLen v = N} @-}

{-@ type ListNE a = {v : [a] | size v > 0} @-}

{-@ measure head1 @-}
{-@ head1 :: ListNE Nat -> Nat @-}
head1 :: [Int] -> Int
head1 (h : t) = h
{-@ measure tail1 @-}
{-@ tail1 :: ListNE Nat -> [Nat] @-}
tail1 :: [Int] -> [Int]
tail1 (h : t) = t

data Ndarray a = N {nDims::[Int], nElts::Either a (Vector (Ndarray a))}

{-@ measure ords @-}
{-@ ords :: Ndarray a -> [Nat] @-}
ords :: Ndarray a -> [Int]
ords (N nDims _nElts) = nDims

{-@ measure isLeft @-}
isLeft (Left _) = True
isLeft (Right _) = False

{-@ data Ndarray a =
 N {nDims::[Nat],
    nElts::{v : Either a (VectorN ({x : Ndarray a | (tail1 nDims) == (ords x)})
                                  {head1 nDims})
        | (isLeft v && size nDims = 0) || (not (isLeft v) && size nDims > 0) }} @-}

{-@ type NdarrayN a N = {v : Ndarray a | nDims v = N} @-}\end{verbatim}
    \caption{Sample implementation of the \texttt{np.ndarray} type in LH}
    \label{lh-nparray}
\end{figure}

\section{Related Work}

As machine learning and linear algebra routines have become more and more popular, there has been an increased interest in statically typing matrix and multidimensional arrays.

\subsection{Vector and Matrix Embeddings}

Eaton makes similar observations about the benefit of highly optimized matrix library code, generally available via the BLAS interface. Using Haskell's type system, Eaton is able to embed the dimensions of vectors and matrices directly into their types. Thus, he is able to get type safe matrix operations. Eaton observes that the Haskell implementation outperforms Octave (another linear algebra programming language) and achieves performance on par with Matlab. However, he laments that the Haskell compiler can generate cryptic errors at locations far removed from the actual dimensionality bugs, making it less ergonomic than desirable \cite{Eaton2006StaticallyTL}. Other packages available on Haskell, such as HMatrix, also provided matrix types with shapes \cite{hmatrix}.

Abe and Sumii achieve similar matrix and vector bindings for OCaml. What is incredible about their bindings is that they use the standard OCaml system to embed the dimension of matrices into their types. OCaml does \textit{not} have any form of dependent typing, so such an embeding is a remarkable achievement \cite{Abe2015ASA}.

Eaton and Abe and Sumii's results are interesting but fall short of the general goal of typing multidimensional arrays since their methods only work for vectors and matrices.

\subsection{Multidimensional Array Embeddings}

Work has been done for the more general case of multidimensional arrays beyond just matrices. In Rink 2018, the author represents the type of multidimensional arrays as lists of integers --- analogous to the shape discussed in Section \ref{multidimensional}. Rink also identifies common operations between the shapes of multidimensional arrays. He includes swapping dimensions, dropping dimensions if they are equal, and concatenating the shapes of two arrays. However, the paper requires that the shapes contain only integers --- no abstract values --- and the arguments to the operators he declares must also be integers. Furthermore, there is no concept of array types which accept an arbitrary number of dimensions \cite{Rink2018ModelingOL}.

Chen 2017 embeds a multidimensional array type in the Scala type system, leveraging Scala's built-in heterogenous list (HList) type. Like Rink, Chen defines and implements several operations over the shape types, including inserting a new dimension and contracting all dimensions that are equal. Unlike Rink, Chen's dimensions are abstract and do not require concrete integers. Also, Chen's dimensions allow for an arbitrary number of dimensions by having the shape be a generic subtype of an HList. Overall, Chen's embedding most closely matches the embedding we desire in Python's type system. It still lacks support for the atypical broadcast operator, and arithmetic between the dimensions of the arrays does not seem to be allowed. Also, it appears that the use of user-provided integers is not possible in the embedding.

\chapter{A Type Calculus for Multidimensional Arrays}

Having seen the semantics of multidimensional arrays and various embeddings in other languages, how can we check the dimensions of arrays within Python while maintaining its ethos? The goal is to increase the strength of the type checker while not exploding the complexity of the syntax. We should be able to annotate many, if not all, of the functions previously described in Section \ref{ndarray-operations}. With these goals in mind, we present a new syntax and extension to Python's existing type system for declaring and checking multidimensional array functions and values.

\section{Syntax}

\begin{figure}
    \centering
    \begin{grammar}
        <type> ::= \ldots
        \alt Nparray <dimension>*

        <dimension> ::= Id <string>
        \alt Int <int>
        \alt Add (<dimension>, <dimension>)
        \alt Mul (<dimension>, <dimension>)
        \alt Spread <string>
        \alt Drop (<string>, (<string> | <int>)*)
        \alt Keep (<string>, (<string> | <int>)*)

        <functionarg> ::= (<string>, <type>)

        <functiontype> ::= (<functionarg>*, <type>)

    \end{grammar}
    \caption{Full syntax for matrix types}
    \label{syntax}
\end{figure}


The major construct is a new \textbf{Nparray} type. This type represents a matrix of certain dimensions. It accepts a list of \textit{dimensions} to represent the concrete or abstract dimensions of the array. \textit{dimensions} have several constructs.
\begin{itemize}
    \item \textbf{Id} --- declares or references an abstract dimension of an array, one that can be of any non-negative length

    \item \textbf{Int} --- declares a dimension that must be exactly a certain size

    \item \textbf{Add} --- declares a dimensions that is the result of adding the sizes of previously declared dimensions. In Python syntax, can be represented by the \texttt{+} operator.

    \item \textbf{Mul} --- declares a dimensions that is the result of multiplying the sizes of previously declared dimensions. In Python, can be represented by the \texttt{*} operator.

    \item \textbf{Spread} --- declares or references an arbitrary number of dimensions that have arbitrary sizes. In Python, can be represented as \texttt{*A} where \texttt{A} could be an arbitrary variable name.

    \item \textbf{Drop} --- references an arbitrary number of dimensions declared by a \textbf{Spread} operation and allows the dropping of one or more of the captured dimensions.

    \item \textbf{Keep} --- references an arbitrary number of dimensions declared by a \textbf{Spread} operation and allows keeping one or more of the captured dimensions, discarding the rest.
\end{itemize}

We represent a function parameter type is a pair between a string --- the name of the parameter --- and a type. A function type is then a pair between a list of function parameter types and a return type.

For arguments to these function, we restrict to \textbf{Nparray} types which have a finite and known number of dimensions, essentially disallowing \textbf{Spread} and related \textit{dimensions} constructors. This currently restricts us to checking function applications and unable to verify the body of functions that use or return the \textbf{Nparray} constructor. Despite this limitation, we can still declare the types for many \texttt{numpy} functions and check their sequential applications. In future work, we can investigate lifting such restrictions and performing checking on function bodies.

See Figure \ref{syntax} for the formal syntax.

\subsection{Examples}

Suppose we would like to annotate the matrix multiplication function in Python with this new syntax. As a general description, matrix multiplication acts on two matrices with two dimensions each. The ``inner'' dimensions of the two matrices must be the same size. The result of the multiplication will be a matrix of two dimensions which correspond to the ``outer'' dimensions of the two original matrices. The definition along with some applications can be found, quite succinctly, in Figure \ref{np-type-matmul}. Here, we can see that the previous weaknesses in \texttt{mypy} allowing for the incorrect number of dimensions or dimensions that do not match has been caught statically.

\begin{figure}
    \centering
    \begin{verbatim}
def matmul(X: Nparray[A, B], Y: Nparray[B, C]) -> Nparray[A, C]: ...

X: Nparray[A, B, C]
Y: Nparray[A, B]
Z: Nparray[B, C]
W: Nparray[C, D]

matmul(X, Y) # will fail, number of dimensions incorrect
matmul(Y, Y) # will fail, inner dimensions don't work
res = matmul(Y, Z) # will succeed
matmul(res, W) # will succeed, res inferred to have type Nparray[A, C]\end{verbatim}
    \caption{Typing of matrix multplication with new types}
    \label{np-type-matmul}
\end{figure}

As a demonstration of the \textbf{Spread} operator, we can also provide a typing annotation for one case of the \texttt{numpy.dot} operator. In this particular case, the first matrix can have an arbitrary number of dimensions. The second matrix must have exactly one dimension, which matches the last dimension of the first matrix. The return type is a matrix which has the same dimensions as the first matrix except the last dimension is removed. All this can be expressed in the type found in Figure \ref{np-type-dot}.

\begin{figure}
    \begin{verbatim}
def dot(X: Nparray[*A, B], Y: Nparray[B]) -> Nparray[*A]: ...

X: Nparray[1, 2, 3, 4]
Y: Nparray[5]
Z: Nparray[4]
W: Nparray[A, A, 5]

dot(X, Y) # will fail, last dimension doesn't match
dot(X, Z) # will succeed, result is Nparray[1, 2, 3]
dot(W, Y) # will succeed, result is Nparray[A, A]\end{verbatim}
    \caption{Typing of \texttt{np.dot} with new types}
    \label{np-type-dot}
\end{figure}

\subsection{Semantics}

We now provide a formal semantics for type checking the types defined above. There are three stores in the context: $\Gamma, \Sigma,$ and $\Pi$. They map single dimension variables to the argument's dimensions, spread variables to a list of argument dimensions, and parameter names to the argument types, respectively.

At a high level, checking falls into three steps:
\begin{enumerate}[label=\arabic*.]
    \item \textbf{Application checking} --- this checks a \textit{function type} against a list of \textit{arg types}. For each parameter in the function type, the type of the parameter is checked against the type of the corresponding argument. If each of the parameter types checks, then we can form the return type from the context. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{A} (param\_types, ret\_type), args : \Gamma', \Sigma', \Pi', \tau$$

    \item \textbf{Parameter/argument checking} --- this checks a specific parameter type against the provided argument type. If the parameter type is an integer, the type checking is straightforward. We simply check that the argument type is an integer, literal integer, or \textbf{Nparray} with 0 dimensions (which is equivalent to a scalar). If the parameter type is an \textbf{Nparray}, after verifying that the argument type is also an \textbf{Nparray}, we need to do further checking of the dimensions of the parameter and argument type. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{P} (type, arg\_type) : \Gamma', \Sigma', \Pi'$$


    \item \textbf{Dimension checking} --- this is the ``lowest'' level of the type checking. Here we will establish equalities and mappings between the dimensions required by the type and those provided in the arguments. For each of the dimension constructs, there are different typing rules. Let \textit{args} represent the dimensions of the argument type. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{D} (dimension, arg\_dimensions) : \Gamma', \Sigma', \Pi', rem\_dimensions$$

    \begin{itemize}
        \item \textbf{Id} \textit{i} --- if \textit{i} is not in $\Gamma$, then map $\Gamma[i \mapsto hd(args)]$ and continue type checking the remaining argument dimensions. If \textit{i} is in $\Gamma$, then prove that $\Gamma(i) = hd(args)$.

        \item \textbf{Int} \textit{i} --- prove that $i = hd(args)$.

        \item \textbf{Add} $(d_1, d_2)$ --- build arithmetic expressions from $d_1$ and $d_2$ resulting in $e_1$ and $e_2$. Prove that $e_1 + e_2 = hd(args)$.

        \item \textbf{Mul} $(d_1, d_2)$ --- build arithmetic expressions from $d_1$ and $d_2$ resulting in $e_1$ and $e_2$. Prove that $e_1 * e_2 = hd(args)$.

        \item \textbf{Spread} \textit{var} --- if \textit{var} is not in $\Sigma$, then find a split of \textit{args} into lists of types \textit{front} and \textit{back} such that $\Sigma[var \mapsto front]$ allows the remainder of type checking to succeed. If \textit{var} is in $\Sigma$, then split \textit{args} into \textit{front} and \textit{back} where $len(front) = len(\Sigma(var))$. For each element of \textit{front} and $\Sigma(var)$, prove that they are equal.

        \item \textbf{Drop} (\textit{var}, \textit{indices}) --- require that $var$ is in $\Sigma$. Convert \textit{indices} to a list of integers and drop those indices from $\Sigma(var)$. The indices can be pulled from $\Pi$ since arguments to the functions can be used to drop dimensions

        \item \textbf{Keep} (\textit{var}, \textit{indices}) --- require that $var$ is in $\Sigma$. Convert \textit{indices} to a list of integers and keep those indices in $\Sigma(var)$.
    \end{itemize}
\end{enumerate}
The formalized semantics for the type checking are provided in Figure \ref{semantics1} and continue in Figure \ref{semantics2}.

\begin{figure}
    $$\textsc{CheckAppEmpty}~\frac{\Gamma, \Sigma, \Pi \vdash_R ret : \tau}{\Gamma, \Sigma, \Pi \vdash_A ([], ret), [] : \Gamma, \Sigma, \Pi, \tau}$$

    $$\textsc{CheckApp}~\frac{\Gamma, \Sigma, \Pi[p \mapsto h_2] \vdash_P h_1, h_2 : \Gamma', \Sigma', \Pi' \qquad \Gamma', \Sigma', \Pi' \vdash_A (t_1, ret), t_2 : \Gamma'', \Sigma'', \Pi'', \tau}{\Gamma, \Sigma, \Pi \vdash_A ((p, h_1) :: t_1, ret), h_2 :: t_2 : \Gamma'', \Sigma'', \Pi'', \tau}$$

    $$\textsc{CheckParamScalarArrArr}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{Nparray}~[]) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarArrInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{Int}) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarArrLitInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{LiteralInt}~i) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarIntArr}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Int}, \textbf{Nparray}~[]) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarLitInt}~\frac{i = j}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{LiteralInt}~i, \textbf{LiteralInt}~j) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamArray}~\frac{\begin{gathered}\Gamma, \Sigma, \Pi \vdash_D h, \ell_2 : \Gamma', \Sigma', \Pi', rem \\ \Gamma', \Sigma', \Pi' \vdash_P (\textbf{Nparray}~\ell_1, \textbf{Nparray}~rem) : \Gamma'', \Sigma'', \Pi''\end{gathered}}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~h :: \ell_1, \textbf{Nparray}~\ell_2) : \Gamma'', \Sigma'', \Pi''}$$

    $$\textsc{CheckDimIdNotFound}~\frac{n \not\in \Gamma}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma[n \mapsto h], \Sigma, \Pi, t}$$

    $$\textsc{CheckDimIdFound}~\frac{n \in \Gamma \qquad \Gamma(n) = h}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimIdFoundInParams}~\frac{n \in \Pi \qquad \Pi(n) = \textbf{LiteralInt}~i \qquad i = h}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimInt}~\frac{h = i}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Int}~i, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimAdd}~\frac{d_1 \rightarrow e_1 \qquad d_2 \rightarrow e_2 \qquad h = e_1 + e_2}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Add}~(d_1, d_2), h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimMul}~\frac{d_1 \rightarrow e_1 \qquad d_2 \rightarrow e_2 \qquad h = e_1 \cdot e_2}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Mul}~(d_1, d_2), h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{TransformId}~\frac{d \in \Gamma}{\Gamma \vdash_T d \rightarrow \Gamma(d)}$$

    $$\textsc{TransformAdd}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2}{\Gamma \vdash_T \textbf{Add}~(d_1, d_2) \rightarrow e_1 + e_2}$$

    $$\textsc{TransformMul}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2}{\Gamma \vdash_T \textbf{Mul}~(d_1, d_2) \rightarrow e_1 + e_2}$$

    \caption{Formal semantics for type checking}
    \label{semantics1}
\end{figure}

\begin{figure}
    $$\textsc{CheckDimSpreadNotFound}~\frac{n \not\in \Sigma}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Spread}~n, front @ back) : \Gamma, \Sigma[n \mapsto front], \Pi, back}$$

    $$\textsc{CheckDimSpreadFound}~\frac{n \in \Sigma \qquad len(front) = len(\Sigma(n)) \qquad front = \Sigma(n)}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Spread}~n, front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{CheckDimDrop}~\frac{n \in \Sigma \qquad \Pi \vdash_L \ell \rightsquigarrow \ell' \qquad drop(\Sigma(n), \ell') = front}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Drop}~(n, \ell), front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{CheckDimKeep}~\frac{n \in \Sigma \qquad \Pi \vdash_L \ell \rightsquigarrow \ell' \qquad keep(\Sigma(n), \ell') = front}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Keep}~(n, \ell), front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{RetInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Int} : \textbf{Int}}$$

    $$\textsc{RetLiteralInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{LiteralInt}~i : \textbf{LiteralInt}~i}$$

    $$\textsc{RetNparrayEmpty}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~[] : \textbf{Nparray}~[]}$$

    $$\textsc{RetNparrayFullId}~\frac{i \in \Gamma \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Id}~i :: t) : \textbf{Nparray}~(\textbf{Id}~i)}$$

    $$\textsc{RetNparrayFullInt}~\frac{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Int}~i :: t) : \textbf{Nparray}~()\textbf{Int}~i :: t')}$$

    $$\textsc{RetNparrayFullAdd}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2 \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Add}~(d_1, d_2) :: t) : \textbf{Nparray}~(\textbf{Add}~(e_1, e_2) :: t')}$$

    $$\textsc{RetNparrayFullMul}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2 \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Mul}~(d_1, d_2) :: t) : \textbf{Nparray}~(\textbf{Mul}~(e_1, e_2) :: t')}$$

    $$\textsc{RetNparrayFullSpread}~\frac{n \in \Sigma \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Spread}~n :: t) : \Sigma(n) @ t'}$$

    $$\textsc{RetNparrayFullDrop}~\frac{n \in \Sigma \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell' \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Drop}~(n, \ell) :: t) : drop(\Sigma(n), \ell') @ t'}$$

    $$\textsc{RetNparrayFullKeep}~\frac{n \in \Sigma \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell' \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Keep}~(n, \ell) :: t) : keep(\Sigma(n), \ell') @ t'}$$

    $$\textsc{TransformListEmpty}~\frac{}{\Gamma \vdash_L [] \rightsquigarrow \ell}$$

    $$\textsc{TransformListInt}~\frac{\Gamma \vdash_L \ell \rightsquigarrow \ell'}{\Gamma \vdash_L i :: \ell \rightsquigarrow i :: \ell'}~i \in \mathbb Z$$

    $$\textsc{TransformListId}~\frac{s \in \Gamma \qquad \Gamma(n) = \textbf{LiteralInt}~i \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell'}{\Gamma \vdash_L s :: \ell \rightsquigarrow i :: \ell'}$$

    \caption{Formal semantics for type checking (continued)}
    \label{semantics2}

\end{figure}

\section{Evaluation}

\subsection{Practicality}

\subsection{Implementation}

\subsection{Shortcomings}

\subsection{Future Work}

\section{Conclusion}


\bibliographystyle{plain}
\bibliography{research}

\end{document}
