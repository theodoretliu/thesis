\documentclass{book}

\usepackage{float}
\usepackage{url}
\usepackage[doublespacing]{setspace}
\usepackage[margin=1.5in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{syntax}
\usepackage{enumitem}
\usepackage{cite}


\begin{document}

\tableofcontents
\newpage

% \begin{abstract}
    Python is an extremely popular programming language used by many companies and academics around the world. Historically a slow language, it has gained popularity as an interface with high performance matrix and machine learning libraries. Although initially a strong, dynamically typed language, recent additions to Python have introduced a static type checker; however, the types are mostly useless when typing matrix operations. In this thesis, we develop a simple type calculus and extension to Python's type system that strengthens the static guarantees of the type checker over matrix operations while not sacrificing the simplicity and ease of use that is core to Python's spirit.
% \end{abstract}

\section{Introduction}

Python is a strong and dynamically typed language focused on simplicity and ease of use. Since its invention in the late 1980s, Python has exploded in popularity, seeing rapid adoption in both academia and industry. Its flexibility and approachable syntax made it user-friendly. An increased interest in scientific computing and machine learning from the Python community led to the creation of packages such as \texttt{numpy} and \texttt{pytorch}, which expose high level APIs for high performance C code, circumventing Python's slow execution and enabling rapid development of machine learning and scientific computing applications.

More recently, Python's dynamic type system has been seen as a weakness rather than a strength. Runtime errors caused by type mismatches can be annoying or potentially disastrous for people deploying Python at scale. To combat this, type annotations were added directly to Python's syntax as part of Python 3.5 in 2014, and a reference typechecker --- \texttt{mypy} --- was developed to statically analyze the annotations. \texttt{mypy} eliminates a whole class of type errors from Python code but is not powerful enough to reject matrices with incompatible dimensions from being multiplied or applied together, resulting in runtime errors in machine learning or scientific computing code.

In this thesis, we propose a new extension to Python's type system that allows the expression of function signatures that respect the dimensions of matrices as they are passed into the function. This contribution further strengthens the type system and makes impossible runtime errors related to the dimensionality of matrices at function application sites.


\chapter{Background and Related Work}

\section{Type Systems}

A type system in a programming language is a form of program analysis where labels called \textbf{types} are assigned to values and expressions. By reasoning about these types, the system can enforce properties about the execution of programs within the language. Types can be thought of as a set of values that a variable or expression can take, and type checking is the process of determining whether a value or set of values belongs to the set declared or specified. Type systems can range from the simple to the complex and are usually designed with certain properties in mind. The simply typed lambda calculus introduced by Church only had function types but guaranteed that the left sides of applications were always functions and that every expression had a normal form \cite{Church1940AFO}. In contrast, Rust-lang's ownership and type system is able to not only prove that its programs invoke functions with the correct arguments but also that concurrent accesses to memory are safe \cite{rustlang}.

In the remainder of this section, we will examine several dichotomies and classes of type systems that will be relevant later in this paper.

\subsection{Static versus Dynamic Type Systems}

In a \textbf{static type system}, the types of a program are checked during the compilation of the program. The type of a function or variable is constant throughout the lifetime of program. The types can be annotated directly or inferred. A static system ensures that no runtime errors relating to the types will occur during the execution of a compiled program. Static type systems benefit greatly from this guarantee and can also use the type information during compilation to perform optimizations. Additionally, type information can be stripped away in the final executable, reducing the size of the resulting program. However, static type systems can be difficult to implement, and their speed slows and complexity grows as the types they seek to support become more complex. C/C++, OCaml, and Rust are examples of languages with static type systems.

In a \textbf{dynamic type system}, the types of values are checked during the execution of a program. Variables can be reassigned to multiple types. Runtime errors will be thrown if there are operations between incompatible types, such as attempting to add a string and a float. Dynamic type systems are good for their flexibility and ease of implementation; there is no need for type checking or inference ahead of execution. However, their lack of runtime guarantees can be difficult to handle, especially in mission-critical software. Without knowing whether a program can fail in a myriad of ways at runtime makes it hard to have confidence in its deployment. Python (traditionally), Ruby, and Javascript are languages with dynamic type systems.

\subsection{Strong versus Weak Type Systems}

A \textbf{strong type system} enforces that the type expected at a particular program location exactly matches the type found. In other words, no implicit conversions are done between types to make function calls or assignments well-typed. If there are mismatches found, an error either during compilation or runtime is raised. Strong type systems prevent users from accidentally misusing variables or performing computations they did not intend. Users need to bear the additional cost of needing explicit type casts or conversions whenever a type \textit{actually} needs to be used as a different type. Python and OCaml are languages with strong type systems.

A \textbf{weak type system} attempts to perform certain type conversions implicitly if types do not match as expected. This eliminates the need for constant massaging between various types --- such as when wanting to print an integer --- but can have disastrous consequences. As an example, Javascript has an infamous weak type system, leading to bizarre and unexpected results from inocuous statements like \texttt{12 + "21" == "1221"}. PHP is another example of a weakly typed language.

\subsection{Other Type Systems}
\paragraph{Duck Typing}

Duck typing receives its name from the classic phrase: ``If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.'' In programming languages, this means the type system does not care about the specific label or class a value belongs to as long as it has certain attributes or implements certain methods. As an example, if we have expression \texttt{x.f()} in a duck typing system, it does not matter whether \texttt{x} is of class A or B or a primitive type, as long as it has a callable method called \texttt{f}. Python is a duck typed language.

\paragraph{Gradual Typing}

In a gradually typed language, type annotations are optional. Wherever type annotations are present, type checking is performed. For unannotated code, type checking is either elided or a generic type of \textit{any} is inferred \cite{PythonDropbox}. Gradual type systems allow the incremental adoption of typing in a codebase. Instead of having to type every line of code in a codebase at once, small parts can be annotated and statically checked while the remaining code falls back to runtime checks. Thus, gradual typing achieves a balance between static and dynamic typing. TypeScript and Python with \texttt{mypy} are languages with gradual typing.

\paragraph{Dependent and Refinement Types}

Dependent type systems extend traditional type systems by allowing values from the language be a part of the type. This allows further specificity of the sets of values that can inhabit a type. As an example,the traditional type \texttt{List int} represents the set of all lists of any length that contain only integers. An analagous dependent type might be \texttt{List int 4}, denoting the set of integer lists which have exactly length 4. We can take this dependent type further with a function
\begin{verbatim}
def f(x: int) -> List int x: ...\end{verbatim}
which represents a function who accepts an integer and returns a list of exactly the length provided. Dependent types allow us to powerfully reason about the static properties of our language and will useful in our reasoning about matrix dimensions later.

Refinement types are a form of dependent types in which the set of values in a type can be filtered by predicates attached to a type. One refinement type system is Liquid Haskell, which embeds refinement types in the Haskell programming language \cite{Jhala2014RefinementTF}. Refinement types offer a convenient way to declare specific types, and we explore this further in a later section.

\section{Python}

Python's type system is largely a standard one: types generally constrain a class of values, but further granularity is not possible. In comparison, dependent types allow for ``stronger'' types that can further constrain the space of well-typed programs. Refinement types are one such dependent type system, allowing the user to write predicates over values of a particular class to constrain them. Liquid Haskell is one such project that seeks to add refinement types to the programming language Haskell.

As an example, of the power of dependent types, and in particular, refinement types, consider the function that accepts a list and an integer for indexing into the list. In Python, the type of such a function can be seen in Figure \ref{python-type-indexing}.

\begin{figure}
\centering
\begin{verbatim}
A = TypeVar('A')
def index(lst: List[A], i: int) -> A: ... \end{verbatim}
\caption{\texttt{index} function type in Python}
\label{python-type-indexing}
\end{figure}
Such a type prevents improper indexing where the second argument is not an integer or where the first argument is not a list. However, such a type declaration still allows for runtime errors to occur, like the invocation \texttt{index([], 1)}. This will raise an \texttt{IndexOutOfBounds} error since \texttt{1} exceeds the maximum index of the empty list.

A stronger type --- one that is possible to declare in Liquid Haskell --- can statically prevent such malformed invocations. See Figure \ref{lh-type-indexing} for the declaration of the type. Although verbose, this type declaration prevents the misuse of the \texttt{index} function and statically raises a type error for the use \texttt{index [] 0}, which Python was unable to do.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ measure size @-}
{-@ size :: [a] -> {v : Int | v >= 0} @-}
size :: [a] -> Int
size [] = 0
size (h : t) = 1 + size t

{-@ index :: {l : [a] | true} -> {v : Int | v < size l && v >= 0} -> a @-}
index :: [a] -> Int -> a
index (h : t) i = if i == 0 then h else index t (i - 1)

test1 = index [1, 2, 3] 0
test2 = index [] 0 {- type error -}\end{verbatim}
    \caption{\texttt{index} function type in Liquid Haskell}
    \label{lh-type-indexing}
\end{figure}


\subsection{Python}

Python was conceived by Guido van Rossum in 1989 and was officially released to the public in 1991. Python is an interpreted rather than compiled language. It has a strong and dynamic type system. Implicit type conversions are generally not performed, and variables can be assigned to values with different types during runtime. Duck typing is allowed: if a method or line of code accesses an object's attribute or method, the runtime is happy to accept \textit{any} object that has the appropriately named method or attribute. Python is mainly an object-oriented and imperative language although it now has aspects of functional languages as well.

Python is well-known for its simplicity, readability, and ease-of-use, and these attributes are a fundamental part of its spirit. To quote ``The Zen of Python'' by Tim Peters (which can be accessed by typing \texttt{import this} into a Python REPL), ``simple is better than complex'' and ``there should be only one --- and preferably only one --- obvious way to do it.''. Python blocks are delimited by whitespace and its syntax closely resembles pseudocode. Variable types are never explicitly declared, memory is automatically managed and garbage collected, returning different types from functions is allowed; it is seemingly the goal of Python to allow the programmer to sanely accomplish whatever they want with little friction. Large companies --- including Google, Instagram, and Dropbox --- all use Python in their systems or research.

\subsection{\texttt{numpy} and other matrix libraries}

Python unlocks a much faster speed of iteration, but it has its shortcomings. Since it is an interpreted language, it can be difficult to achieve performant code. Python does have a bytecode format which can speed up interpretation, but it is order of magnitudes slower than other compiled languages.

As more and more people began to use Python for scientific and machine learning purposes, its speed increasingly became a barrier. This slowness led to the development of the library \texttt{numpy} which exposes a high-level API for declaring matrices and then performing operations on those matrices. \texttt{numpy} achieves fast performance by implementing all of its algorithms in highly optimized and parallel C code and then linking those into Python. Machine learning libraries such as \texttt{pytorch} and \texttt{tensorflow} took similar approaches, providing high-level APIs for model training while using optimized GPU code to provide speed and parallelism.

The advent of these libraries has allowed engineers and researchers to continue to leverage the flexibility of Python while not sacrificing the speed of their execution and model training.

\subsection{\texttt{mypy} --- Python Typing}

Recently, dynamic typing in Python has become seen as a weakness rather than a strength, especially in large organizations. While Python's flexibility initially made development fast and easy, this did not scale as more engineers began to work on the codebase. Not only were runtime errors possible, it was also difficult to look at functions and immediately determine their expectations for the type of their inputs and outputs. This emphasizes the fact that types not only function as a form of safety for a program but also as a form of self-documentation. Jukka Lehtosalo recognized these weaknesses and, along with the help of Guido and others, developed a static type system and checker for Python --- \texttt{mypy}. As part of PEP 484, Python was officially extended with type annotation in version 3.5 in 2015.

There are now several type checkers for Python including \texttt{pyre} from Facebook and \texttt{pytype} from Google. They are all gradual type checkers. Types can optionally be added anywhere in the source files. For annotated code, the types are checked. Elsewhere, types are assumed to be dynamic and are automatically accepted. This allows the typing to be incrementally adopted throughout a codebase, making it easy for users to opt in to checking where they want it without having to type their entire codebase. As of September 2019, Dropbox had reportedly typed 4 million lines of their Python code.

We now give an overview of the types that \texttt{mypy} supports.
\begin{itemize}
    \item \textbf{Primitives} --- Python's primitive types such as \texttt{int}, \texttt{float}, \texttt{bool}, and \texttt{str} are supported.

    \item \textbf{Collections} --- Python's standard collections like lists, dictionaries, tuples, and sets are supported. They are declared as \texttt{List[Type]}, \texttt{Dict[Type, Type]}, \texttt{Tuple[Type]}, and \texttt{Set[Type]} respectively. These types are parameterized and can be instantiated with different types.

    \item \textbf{Classes and Objects} --- all declared classes are automatically promoted to types, meaning that functions can accept parameters of certain classes. Furthermore, inheritance is automatically viewed as a form of subtyping. As an example,

    \begin{singlespace*}
    \begin{verbatim}
class A:
    pass

class B(A):
    pass

def f(x: A):
    return None

b = B()
f(b) # will type check\end{verbatim}
    \end{singlespace*}
    In the example, all instances of class \texttt{B} are subtypes of class \texttt{A}, so instances of class \texttt{B} can stand in for class \texttt{A} as seen in function \texttt{f} and its application to \texttt{b}.

    \item \textbf{Union types} --- union types are created via the \texttt{Union[Type1, Type2]} operator, allowing a value to be assigned to something from either of the two types.

    \item \textbf{Option types} --- \texttt{mypy} also provides support for option types via \texttt{Optional[Type]}. Although languages with option types typicall have explicit \texttt{None} and \texttt{Some x} constructors, Python simplifies this by having a \texttt{None} and a bare value \texttt{x} for the \texttt{Some} case.

    \item \textbf{Duck typing} --- Python is a duck-typed language, and \texttt{mypy} makes this support explicit via some types. For example, the type \texttt{Iterable[Type]} accepts any object which implements the \texttt{.next()} method and returns the type \texttt{Type}. Similarly, \texttt{Mapping[Type1, Type2]} accepts any object which implements the method \texttt{.__getitem__(x: Type1)} and returns the type \texttt{Type2}. In both of these examples, the exact type of the object does not matter, only that it implements a specific set of methods.

    \item \textbf{Function overloading} --- in \texttt{mypy}, function signatures can be overloaded, meaning that functions can have multiple signatures. This is enabled via the \texttt{@overload} decorator on function. As an example:

    \begin{singlespace*}
    \begin{verbatim}
@overload
def f(x: int) -> str: ...

@overload
def f(x: str) -> int: ...

def f(x: Union[int, str]) -> Union[int, str]:
    if isinstance(x, int):
        return "hello"

    return 1

f(1) # will type check with type str
f('hello') # will type check with type int\end{verbatim}
    \end{singlespace*}
    Because of the \texttt{overload}, \texttt{mypy} is able to infer a much more specific type for each of the function calls rather than just \texttt{Union[int, str]}.

    \item \textbf{Literal values} --- \texttt{mypy} is not a general dependent type checker, but it does have a construct \texttt{Literal[Value]} which requires that a parameter or variable be assigned to exactly the value specified in the \texttt{Literal} constructor. For example,

    \begin{singlespace*}
        \begin{verbatim}
x : Literal[1]

x = 1 # will type check
x = 2 # will not type check
x = 3 - 2 # will not type check\end{verbatim}
    \end{singlespace*}
    Note that although in the last line above, it is ``obvious'' that \texttt{x} is being assigned to 1, \texttt{mypy} performs no reasoning or speculation about the result of $3 - 2$. This is limiting but greatly simplifies the task of checking \texttt{Literal} constructors.

\end{itemize}

\subsection{Dependent and Refinement Types}

Python's type system is largely a standard one: types generally constrain a class of values, but further granularity is not possible. In comparison, dependent types allow for ``stronger'' types that can further constrain the space of well-typed programs. Refinement types are one such dependent type system, allowing the user to write predicates over values of a particular class to constrain them. Liquid Haskell is one such project that seeks to add refinement types to the programming language Haskell.

As an example, of the power of dependent types, and in particular, refinement types, consider the function that accepts a list and an integer for indexing into the list. In Python, the type of such a function can be seen in Figure \ref{python-type-indexing}.

\begin{figure}
\centering
\begin{verbatim}
A = TypeVar('A')
def index(lst: List[A], i: int) -> A: ... \end{verbatim}
\caption{\texttt{index} function type in Python}
\label{python-type-indexing}
\end{figure}
Such a type prevents improper indexing where the second argument is not an integer or where the first argument is not a list. However, such a type declaration still allows for runtime errors to occur, like the invocation \texttt{index([], 1)}. This will raise an \texttt{IndexOutOfBounds} error since \texttt{1} exceeds the maximum index of the empty list.

A stronger type --- one that is possible to declare in Liquid Haskell --- can statically prevent such malformed invocations. See Figure \ref{lh-type-indexing} for the declaration of the type. Although verbose, this type declaration prevents the misuse of the \texttt{index} function and statically raises a type error for the use \texttt{index [] 0}, which Python was unable to do.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ measure size @-}
{-@ size :: [a] -> {v : Int | v >= 0} @-}
size :: [a] -> Int
size [] = 0
size (h : t) = 1 + size t

{-@ index :: {l : [a] | true} -> {v : Int | v < size l && v >= 0} -> a @-}
index :: [a] -> Int -> a
index (h : t) i = if i == 0 then h else index t (i - 1)

test1 = index [1, 2, 3] 0
test2 = index [] 0 {- type error -}\end{verbatim}
    \caption{\texttt{index} function type in Liquid Haskell}
    \label{lh-type-indexing}
\end{figure}


\section{Shortcomings of Existing Type Systems}

The fundamental tension between these type systems is their expressiveness and specificity versus their verbosity and ease of use.

\subsection{\texttt{mypy}}

\texttt{mypy} takes a relatively lightweight approach to type checking. Its simplicity follows the ethos of Python quite closely. Even with its gradual  and sipmle approach, \texttt{mypy} is still able to eliminate a whole class errors, such as invoking functions with inappropriate arguments, accessing attributes that do not exist, or neglecting to check for the ``\texttt{None}-ness'' of function returns.

Still, as seen in Figure \ref{python-type-indexing}, Python still allows for rather obvious errors to occur, and this situation only becomes worse in the case of matrix types. As an example, the best \texttt{mypy} can do for matrix multiplication is seen in Figure \ref{python-type-matmul}. Here, the function type adds little information; it is unlikely that users will attempt to pass anything except \texttt{np.ndarray}. In the code contexts that \texttt{matmul} would occur, it is likely that almost \textit{all} objects are \texttt{np.ndarray}s. This type is so permissive of \texttt{np.ndarray}s that even matrices that do not have exactly two dimensions can be passed into the function without type errors being raised. The type signature does little to prevent runtime errors relating to the shape of the matrices.

\begin{figure}
    \centering
    \begin{verbatim}
import numpy as np

def matmul(x: np.ndarray, y: np.ndarray) -> np.ndarray: ...\end{verbatim}
    \caption{Sample \texttt{mypy} for \texttt{matmul}}
    \label{python-type-matmul}
\end{figure}


\subsection{Liquid Haskell}

Liquid Haskell (LH) has almost the opposite mentality of \texttt{mypy}. LH can represent extremely precise types and make very powerful static deductions about what can and cannot happen at runtime. However, this power and precision is also a downside. Declaring the proper types can be cumbersome and verbose. Furthermore, using these types in function types and then type checking them can be an expensive process. As an experiment, we declared the \texttt{np.nparray} in LH such that we could refer to the dimensions of the \texttt{np.nparray} in function signatures. The representation can be found in Figure \ref{lh-nparray}.

\begin{figure}
    \centering
    \begin{verbatim}
{-@ LIQUID "--exact-data-con" @-}
{-@ LIQUID "--reflection" @-}
{-@ LIQUID "--ple" @-}

import Prelude hiding (reverse, max, drop)

{-@ type Nat = {v: Int | v >= 0} @-}

{-@ measure size @-}
{-@ size :: [a] -> Nat @-}
size :: [a] -> Int
size [] = 0
size (hd : tl) = 1 + size tl

data Vector a = V {vLen::Int, elts::[a]} deriving (Eq)
{-@ data Vector a = V {vLen::Nat, elts::{v : [a] | size v == vLen}} @-}
{-@ type VectorN a N = {v : Vector a | vLen v = N} @-}

{-@ type ListNE a = {v : [a] | size v > 0} @-}

{-@ measure head1 @-}
{-@ head1 :: ListNE Nat -> Nat @-}
head1 :: [Int] -> Int
head1 (h : t) = h

{-@ measure tail1 @-}
{-@ tail1 :: ListNE Nat -> [Nat] @-}
tail1 :: [Int] -> [Int]
tail1 (h : t) = t

data Nparray a = N {nDims::[Int], nElts::Either a (Vector (Nparray a))}

{-@ measure ords @-}
{-@ ords :: Nparray a -> [Nat] @-}
ords :: Nparray a -> [Int]
ords (N nDims _nElts) = nDims

{-@ measure isLeft @-}
isLeft (Left _) = True
isLeft (Right _) = False

{-@ data Nparray a =
 N {nDims::[Nat],
    nElts::{v : Either a (VectorN ({x : Nparray a | (tail1 nDims) == (ords x)}) {head1 nDims})
            | (isLeft v && size nDims = 0) || (not (isLeft v) && size nDims > 0) }} @-}

{-@ type NparrayN a N = {v : Nparray a | nDims v = N} @-}\end{verbatim}

    \caption{Sample implementation of the \texttt{np.ndarray} type in LH}
    \label{lh-nparray}


\end{figure}

This is not a fun representation to work with. Admittedly, little time was spent on making this representation as compact as possible, and we do not claim to be experts in Liquid Haskell. Still, in comparison to the entire Python typing ecosystem, it is clear that bolting on a full refinement type system would be a gross violation of Python's ethos of simplicity and ease of use.
\newpage

\section{A Simple Type Calculus for Matrix Dimensions}

How can we check matrix dimensions while maintaining the Python ethos? In this section, we introduce a new type as well as several operators to Python's type annotations that will enable checking of the dimensionality of matrices. The scope of the types is purposefully limited to matrices, to avoid the explosion in complexity of a more general system.

\subsection{Syntax}

\begin{figure}
    \centering
    \begin{grammar}
        <type> ::= \ldots
        \alt Nparray <dimension>*

        <dimension> ::= Id <string>
        \alt Int <int>
        \alt Add (<dimension>, <dimension>)
        \alt Mul (<dimension>, <dimension>)
        \alt Spread <string>
        \alt Drop (<string>, (<string> | <int>)*)
        \alt Keep (<string>, (<string> | <int>)*)

        <functionarg> ::= (<string>, <type>)

        <functiontype> ::= (<functionarg>*, <type>)

    \end{grammar}
    \caption{Full syntax for matrix types}
    \label{syntax}
\end{figure}


The major construct is a new \textbf{Nparray} type. This type represents a matrix of certain dimensions. It accepts a list of \textit{dimensions} to represent the concrete or abstract dimensions of the array. \textit{dimensions} have several constructs.
\begin{itemize}
    \item \textbf{Id} --- declares or references an abstract dimension of an array, one that can be of any non-negative length

    \item \textbf{Int} --- declares a dimension that must be exactly a certain size

    \item \textbf{Add} --- declares a dimensions that is the result of adding the sizes of previously declared dimensions. In Python syntax, can be represented by the \texttt{+} operator.

    \item \textbf{Mul} --- declares a dimensions that is the result of multiplying the sizes of previously declared dimensions. In Python, can be represented by the \texttt{*} operator.

    \item \textbf{Spread} --- declares or references an arbitrary number of dimensions that have arbitrary sizes. In Python, can be represented as \texttt{*A} where \texttt{A} could be an arbitrary variable name.

    \item \textbf{Drop} --- references an arbitrary number of dimensions declared by a \textbf{Spread} operation and allows the dropping of one or more of the captured dimensions.

    \item \textbf{Keep} --- references an arbitrary number of dimensions declared by a \textbf{Spread} operation and allows keeping one or more of the captured dimensions, discarding the rest.
\end{itemize}

We represent a function parameter type is a pair between a string --- the name of the parameter --- and a type. A function type is then a pair between a list of function parameter types and a return type.

For arguments to these function, we restrict to \textbf{Nparray} types which have a finite and known number of dimensions, essentially disallowing \textbf{Spread} and related \textit{dimensions} constructors. This currently restricts us to checking function applications and unable to verify the body of functions that use or return the \textbf{Nparray} constructor. Despite this limitation, we can still declare the types for many \texttt{numpy} functions and check their sequential applications. In future work, we can investigate lifting such restrictions and performing checking on function bodies.

See Figure \ref{syntax} for the formal syntax.

\subsection{Examples}

Suppose we would like to annotate the matrix multiplication function in Python with this new syntax. As a general description, matrix multiplication acts on two matrices with two dimensions each. The ``inner'' dimensions of the two matrices must be the same size. The result of the multiplication will be a matrix of two dimensions which correspond to the ``outer'' dimensions of the two original matrices. The definition along with some applications can be found, quite succinctly, in Figure \ref{np-type-matmul}. Here, we can see that the previous weaknesses in \texttt{mypy} allowing for the incorrect number of dimensions or dimensions that do not match has been caught statically.

\begin{figure}
    \centering
    \begin{verbatim}
def matmul(X: Nparray[A, B], Y: Nparray[B, C]) -> Nparray[A, C]: ...

X: Nparray[A, B, C]
Y: Nparray[A, B]
Z: Nparray[B, C]
W: Nparray[C, D]

matmul(X, Y) # will fail, number of dimensions incorrect
matmul(Y, Y) # will fail, inner dimensions don't work
res = matmul(Y, Z) # will succeed
matmul(res, W) # will succeed, res inferred to have type Nparray[A, C]\end{verbatim}
    \caption{Typing of matrix multplication with new types}
    \label{np-type-matmul}
\end{figure}

As a demonstration of the \textbf{Spread} operator, we can also provide a typing annotation for one case of the \texttt{numpy.dot} operator. In this particular case, the first matrix can have an arbitrary number of dimensions. The second matrix must have exactly one dimension, which matches the last dimension of the first matrix. The return type is a matrix which has the same dimensions as the first matrix except the last dimension is removed. All this can be expressed in the type found in Figure \ref{np-type-dot}.

\begin{figure}
    \begin{verbatim}
def dot(X: Nparray[*A, B], Y: Nparray[B]) -> Nparray[*A]: ...

X: Nparray[1, 2, 3, 4]
Y: Nparray[5]
Z: Nparray[4]
W: Nparray[A, A, 5]

dot(X, Y) # will fail, last dimension doesn't match
dot(X, Z) # will succeed, result is Nparray[1, 2, 3]
dot(W, Y) # will succeed, result is Nparray[A, A]\end{verbatim}
    \caption{Typing of \texttt{np.dot} with new types}
    \label{np-type-dot}
\end{figure}

\subsection{Semantics}

We now provide a formal semantics for type checking the types defined above. There are three stores in the context: $\Gamma, \Sigma,$ and $\Pi$. They map single dimension variables to the argument's dimensions, spread variables to a list of argument dimensions, and parameter names to the argument types, respectively.

At a high level, checking falls into three steps:
\begin{enumerate}[label=\arabic*.]
    \item \textbf{Application checking} --- this checks a \textit{function type} against a list of \textit{arg types}. For each parameter in the function type, the type of the parameter is checked against the type of the corresponding argument. If each of the parameter types checks, then we can form the return type from the context. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{A} (param\_types, ret\_type), args : \Gamma', \Sigma', \Pi', \tau$$

    \item \textbf{Parameter/argument checking} --- this checks a specific parameter type against the provided argument type. If the parameter type is an integer, the type checking is straightforward. We simply check that the argument type is an integer, literal integer, or \textbf{Nparray} with 0 dimensions (which is equivalent to a scalar). If the parameter type is an \textbf{Nparray}, after verifying that the argument type is also an \textbf{Nparray}, we need to do further checking of the dimensions of the parameter and argument type. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{P} (type, arg\_type) : \Gamma', \Sigma', \Pi'$$


    \item \textbf{Dimension checking} --- this is the ``lowest'' level of the type checking. Here we will establish equalities and mappings between the dimensions required by the type and those provided in the arguments. For each of the dimension constructs, there are different typing rules. Let \textit{args} represent the dimensions of the argument type. Represented by the relation
    $$\Gamma, \Sigma, \Pi \vdash_{D} (dimension, arg\_dimensions) : \Gamma', \Sigma', \Pi', rem\_dimensions$$

    \begin{itemize}
        \item \textbf{Id} \textit{i} --- if \textit{i} is not in $\Gamma$, then map $\Gamma[i \mapsto hd(args)]$ and continue type checking the remaining argument dimensions. If \textit{i} is in $\Gamma$, then prove that $\Gamma(i) = hd(args)$.

        \item \textbf{Int} \textit{i} --- prove that $i = hd(args)$.

        \item \textbf{Add} $(d_1, d_2)$ --- build arithmetic expressions from $d_1$ and $d_2$ resulting in $e_1$ and $e_2$. Prove that $e_1 + e_2 = hd(args)$.

        \item \textbf{Mul} $(d_1, d_2)$ --- build arithmetic expressions from $d_1$ and $d_2$ resulting in $e_1$ and $e_2$. Prove that $e_1 * e_2 = hd(args)$.

        \item \textbf{Spread} \textit{var} --- if \textit{var} is not in $\Sigma$, then find a split of \textit{args} into lists of types \textit{front} and \textit{back} such that $\Sigma[var \mapsto front]$ allows the remainder of type checking to succeed. If \textit{var} is in $\Sigma$, then split \textit{args} into \textit{front} and \textit{back} where $len(front) = len(\Sigma(var))$. For each element of \textit{front} and $\Sigma(var)$, prove that they are equal.

        \item \textbf{Drop} (\textit{var}, \textit{indices}) --- require that $var$ is in $\Sigma$. Convert \textit{indices} to a list of integers and drop those indices from $\Sigma(var)$. The indices can be pulled from $\Pi$ since arguments to the functions can be used to drop dimensions

        \item \textbf{Keep} (\textit{var}, \textit{indices}) --- require that $var$ is in $\Sigma$. Convert \textit{indices} to a list of integers and keep those indices in $\Sigma(var)$.
    \end{itemize}
\end{enumerate}
The formalized semantics for the type checking are provided in Figure \ref{semantics1} and continue in Figure \ref{semantics2}.

\begin{figure}
    $$\textsc{CheckAppEmpty}~\frac{\Gamma, \Sigma, \Pi \vdash_R ret : \tau}{\Gamma, \Sigma, \Pi \vdash_A ([], ret), [] : \Gamma, \Sigma, \Pi, \tau}$$

    $$\textsc{CheckApp}~\frac{\Gamma, \Sigma, \Pi[p \mapsto h_2] \vdash_P h_1, h_2 : \Gamma', \Sigma', \Pi' \qquad \Gamma', \Sigma', \Pi' \vdash_A (t_1, ret), t_2 : \Gamma'', \Sigma'', \Pi'', \tau}{\Gamma, \Sigma, \Pi \vdash_A ((p, h_1) :: t_1, ret), h_2 :: t_2 : \Gamma'', \Sigma'', \Pi'', \tau}$$

    $$\textsc{CheckParamScalarArrArr}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{Nparray}~[]) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarArrInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{Int}) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarArrLitInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~[], \textbf{LiteralInt}~i) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarIntArr}~\frac{}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Int}, \textbf{Nparray}~[]) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamScalarLitInt}~\frac{i = j}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{LiteralInt}~i, \textbf{LiteralInt}~j) : \Gamma, \Sigma, \Pi}$$

    $$\textsc{CheckParamArray}~\frac{\begin{gathered}\Gamma, \Sigma, \Pi \vdash_D h, \ell_2 : \Gamma', \Sigma', \Pi', rem \\ \Gamma', \Sigma', \Pi' \vdash_P (\textbf{Nparray}~\ell_1, \textbf{Nparray}~rem) : \Gamma'', \Sigma'', \Pi''\end{gathered}}{\Gamma, \Sigma, \Pi \vdash_P (\textbf{Nparray}~h :: \ell_1, \textbf{Nparray}~\ell_2) : \Gamma'', \Sigma'', \Pi''}$$

    $$\textsc{CheckDimIdNotFound}~\frac{n \not\in \Gamma}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma[n \mapsto h], \Sigma, \Pi, t}$$

    $$\textsc{CheckDimIdFound}~\frac{n \in \Gamma \qquad \Gamma(n) = h}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimIdFoundInParams}~\frac{n \in \Pi \qquad \Pi(n) = \textbf{LiteralInt}~i \qquad i = h}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Id}~n, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimInt}~\frac{h = i}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Int}~i, h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimAdd}~\frac{d_1 \rightarrow e_1 \qquad d_2 \rightarrow e_2 \qquad h = e_1 + e_2}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Add}~(d_1, d_2), h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{CheckDimMul}~\frac{d_1 \rightarrow e_1 \qquad d_2 \rightarrow e_2 \qquad h = e_1 \cdot e_2}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Mul}~(d_1, d_2), h :: t) : \Gamma, \Sigma, \Pi, t}$$

    $$\textsc{TransformId}~\frac{d \in \Gamma}{\Gamma \vdash_T d \rightarrow \Gamma(d)}$$

    $$\textsc{TransformAdd}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2}{\Gamma \vdash_T \textbf{Add}~(d_1, d_2) \rightarrow e_1 + e_2}$$

    $$\textsc{TransformMul}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2}{\Gamma \vdash_T \textbf{Mul}~(d_1, d_2) \rightarrow e_1 + e_2}$$

    \caption{Formal semantics for type checking}
    \label{semantics1}
\end{figure}

\begin{figure}
    $$\textsc{CheckDimSpreadNotFound}~\frac{n \not\in \Sigma}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Spread}~n, front @ back) : \Gamma, \Sigma[n \mapsto front], \Pi, back}$$

    $$\textsc{CheckDimSpreadFound}~\frac{n \in \Sigma \qquad len(front) = len(\Sigma(n)) \qquad front = \Sigma(n)}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Spread}~n, front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{CheckDimDrop}~\frac{n \in \Sigma \qquad \Pi \vdash_L \ell \rightsquigarrow \ell' \qquad drop(\Sigma(n), \ell') = front}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Drop}~(n, \ell), front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{CheckDimKeep}~\frac{n \in \Sigma \qquad \Pi \vdash_L \ell \rightsquigarrow \ell' \qquad keep(\Sigma(n), \ell') = front}{\Gamma, \Sigma, \Pi \vdash_D (\textbf{Keep}~(n, \ell), front @ back) : \Gamma, \Sigma, \Pi, back}$$

    $$\textsc{RetInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Int} : \textbf{Int}}$$

    $$\textsc{RetLiteralInt}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{LiteralInt}~i : \textbf{LiteralInt}~i}$$

    $$\textsc{RetNparrayEmpty}~\frac{}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~[] : \textbf{Nparray}~[]}$$

    $$\textsc{RetNparrayFullId}~\frac{i \in \Gamma \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Id}~i :: t) : \textbf{Nparray}~(\textbf{Id}~i)}$$

    $$\textsc{RetNparrayFullInt}~\frac{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Int}~i :: t) : \textbf{Nparray}~()\textbf{Int}~i :: t')}$$

    $$\textsc{RetNparrayFullAdd}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2 \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Add}~(d_1, d_2) :: t) : \textbf{Nparray}~(\textbf{Add}~(e_1, e_2) :: t')}$$

    $$\textsc{RetNparrayFullMul}~\frac{\Gamma \vdash_T d_1 \rightarrow e_1 \qquad \Gamma \vdash_T d_2 \rightarrow e_2 \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Mul}~(d_1, d_2) :: t) : \textbf{Nparray}~(\textbf{Mul}~(e_1, e_2) :: t')}$$

    $$\textsc{RetNparrayFullSpread}~\frac{n \in \Sigma \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Spread}~n :: t) : \Sigma(n) @ t'}$$

    $$\textsc{RetNparrayFullDrop}~\frac{n \in \Sigma \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell' \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Drop}~(n, \ell) :: t) : drop(\Sigma(n), \ell') @ t'}$$

    $$\textsc{RetNparrayFullKeep}~\frac{n \in \Sigma \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell' \qquad \Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~t : \textbf{Nparray}~t'}{\Gamma, \Sigma, \Pi \vdash_R \textbf{Nparray}~(\textbf{Keep}~(n, \ell) :: t) : keep(\Sigma(n), \ell') @ t'}$$

    $$\textsc{TransformListEmpty}~\frac{}{\Gamma \vdash_L [] \rightsquigarrow \ell}$$

    $$\textsc{TransformListInt}~\frac{\Gamma \vdash_L \ell \rightsquigarrow \ell'}{\Gamma \vdash_L i :: \ell \rightsquigarrow i :: \ell'}~i \in \mathbb Z$$

    $$\textsc{TransformListId}~\frac{s \in \Gamma \qquad \Gamma(n) = \textbf{LiteralInt}~i \qquad \Gamma \vdash_L \ell \rightsquigarrow \ell'}{\Gamma \vdash_L s :: \ell \rightsquigarrow i :: \ell'}$$

    \caption{Formal semantics for type checking (continued)}
    \label{semantics2}

\end{figure}

\section{Evaluation}

\subsection{Practicality}

\subsection{Implementation}

\subsection{Shortcomings}

\subsection{Future Work}

\section{Conclusion}


\bibliographystyle{plain}
\bibliography{research}

\end{document}
